#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Mix Analyzer v7.3 - BETA RELEASE
================================

ARCHITECTURE PRINCIPLES:
1. Calculate scores LANGUAGE-NEUTRAL (no idioma en l√≥gica)
2. Freeze score before translation (score congelado)
3. Translate messages with Mat√≠as Voice (del eBook "Mastering Ready")

KEY IMPROVEMENTS from v6:
-------------------------
‚úÖ MASTER ANALYSIS COMPLETE - Aspectos correctos + Observaciones t√©cnicas
‚úÖ TRUE PEAK CONTEXT - "Lo que hace la industria real" + "tus o√≠dos deciden"
‚úÖ CTAS CONVERSACIONALES - Bifurcaci√≥n clara DIY vs Servicio
‚úÖ BUG FIXES - reduction_needed formula + unit duplication
‚úÖ COMMERCIAL FOCUS - Tool serves mastering service CTAs

KEY IMPROVEMENTS from v5:
-------------------------
‚úÖ STRICT MODE MORE DEMANDING (5-7 point difference from normal)
‚úÖ MASTERED FILE DETECTION with confidence levels
‚úÖ ELIMINATED "remasterizar" - replaced with "volver a mezcla original"
‚úÖ STEREO WIDTH strict/normal modes

RESULT:
-------
Same file ‚Üí Same score in EN/ES
Different language ‚Üí Same technical truth, different narrative (Mat√≠as Voice)
Strict mode ‚Üí Significantly more demanding (senior engineer perspective)
Master detection ‚Üí Complete analysis with positive aspects + observations

Author: Mat√≠as Carvajal Garc√≠a (@matcarvy)
Based on: "Mastering Ready - Asegura el √©xito de tu mastering desde la mezcla" eBook
Version: 7.3.0-beta (2025-12-22)

Usage:
------
  python mix_analyzer.py archivo.wav --lang es --write
  python mix_analyzer.py archivo.wav --lang en --strict
  python mix_analyzer.py archivo.wav --short --lang es
"""
from __future__ import annotations

import argparse
import json
import math
import sys
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

import numpy as np
import soundfile as sf
import librosa
from scipy.signal import resample_poly

try:
    import pyloudnorm as pyln  # type: ignore
    HAS_PYLOUDNORM = True
except Exception:
    HAS_PYLOUDNORM = False


# ----------------------------
# Utility Functions
# ----------------------------
def strip_unit(s: str) -> str:
    """
    Remove unit suffixes from metric values to avoid duplication.
    
    Example:
        strip_unit("-2.5 dBFS") ‚Üí "-2.5"
        strip_unit("0.4 dBTP") ‚Üí "0.4"
    
    This prevents formatting like "-2.5 dBFS dBFS" when concatenating.
    """
    if not isinstance(s, str):
        return str(s)
    return s.replace(" dBFS", "").replace(" dBTP", "").replace(" dB", "").replace(" LUFS", "").strip()


# ----------------------------
# Constants
# ----------------------------
MIN_DURATION_FOR_LUFS = 3.0  # segundos m√≠nimos para LUFS confiable
DC_OFFSET_THRESHOLD = 0.01   # umbral para advertencia de DC offset

# ----------------------------
# Localization helpers
# ----------------------------
METRIC_NAMES = {
    "en": {
        "Headroom": "Headroom",
        "True Peak": "True Peak",
        "DC Offset": "DC Offset",
        "LUFS (Integrated)": "LUFS (Integrated)",
        "PLR": "PLR",
        "Crest Factor": "Crest Factor",
        "Stereo Width": "Stereo Width",
        "Frequency Balance": "Frequency Balance",
    },
    "es": {
        "Headroom": "Headroom",
        "True Peak": "True Peak",
        "DC Offset": "DC Offset",
        "LUFS (Integrated)": "LUFS (Integrated)",
        "PLR": "PLR",
        "Crest Factor": "Crest Factor",
        "Stereo Width": "Ancho Est√©reo",
        "Frequency Balance": "Balance de Frecuencias",
    },
}

UI_TEXT = {
    "en": {
        "analyzing": "üéµ Analyzing",
        "analysis_results": "ANALYSIS RESULTS",
        "saved_json": "‚úÖ Report saved to",
        "save_error": "‚ùå Error saving JSON",
        "invalid_oversample": "‚ùå Error: oversample must be 1, 2, 4, or auto",
        "short_header": "üß† Quick Summary",
        "short_separator": "‚îÄ" * 50,
    },
    "es": {
        "analyzing": "üéµ Analizando",
        "analysis_results": "RESULTADOS DEL AN√ÅLISIS",
        "saved_json": "‚úÖ Reporte guardado en",
        "save_error": "‚ùå Error guardando JSON",
        "invalid_oversample": "‚ùå Error: oversample debe ser 1, 2, 4, o auto",
        "short_header": "üß† Resumen R√°pido",
        "short_separator": "‚îÄ" * 50,
    },
}


# ----------------------------
# UNIFIED SCORING ENGINE (Track 1)
# Language-neutral calculations
# ----------------------------

class ScoringThresholds:
    """
    Unified thresholds - NO language dependency
    Single source of truth for ALL scoring logic
    """
    
    HEADROOM = {
        "strict": {
            "critical": lambda peak: peak >= -1.0,
            "warning": lambda peak: (-4.0 <= peak < -1.0),  # M√°s amplio: incluye -4 a -2
            "perfect": lambda peak: -6.0 <= peak <= -5.0,   # M√°s estrecho
            "pass": lambda peak: (-9.0 <= peak < -6.0) or (-5.0 < peak < -4.0),  # Solo perfecto y bajo
            "conservative": lambda peak: -12.0 <= peak < -9.0,
        },
        "normal": {
            "critical": lambda peak: peak >= -1.0,
            "warning": lambda peak: -2.0 < peak < -1.0,
            "perfect": lambda peak: -6.0 <= peak <= -3.0,
            "pass": lambda peak: -9.0 <= peak < -3.0,
            "conservative": lambda peak: -12.0 <= peak < -9.0,
        }
    }
    
    TRUE_PEAK = {
        "strict": {
            "critical": lambda tp: tp >= -0.5,
            "warning": lambda tp: -3.0 < tp < -0.5,  # Expandido: incluye -3 a -0.5
            "perfect": lambda tp: tp <= -3.0,
            "pass": lambda tp: False,  # Eliminado: solo perfect o warning/critical
        },
        "normal": {
            "critical": lambda tp: tp >= -0.5,
            "warning": lambda tp: -1.0 < tp < -0.5,
            "perfect": lambda tp: tp <= -3.0,
            "pass": lambda tp: -3.0 < tp <= -1.0,
        }
    }
    
    PLR = {
        "strict": {
            "perfect": lambda plr: plr >= 14.0,
            "pass": lambda plr: 12.0 <= plr < 14.0,      # M√°s alto: antes era 10
            "warning": lambda plr: 10.0 <= plr < 12.0,    # NUEVO rango
            "critical": lambda plr: plr < 10.0,           # Lo que era 7-10 ahora es critical
        },
        "normal": {
            "perfect": lambda plr: plr >= 12.0,
            "pass": lambda plr: 8.0 <= plr < 12.0,
            "warning": lambda plr: 6.0 <= plr < 8.0,
            "critical": lambda plr: plr < 6.0,
        }
    }
    
    STEREO_WIDTH = {
        "strict": {
            "perfect": lambda corr: 0.75 <= corr <= 0.85,  # M√°s estrecho que normal
            "pass": lambda corr: (0.70 <= corr < 0.75) or (0.85 < corr <= 0.90),
            "warning": lambda corr: (0.60 <= corr < 0.70) or (0.90 < corr <= 0.95) or (-0.2 < corr < 0.60),
            "critical": lambda corr: -0.5 <= corr <= -0.2,
            "catastrophic": lambda corr: corr < -0.5,  # Antifase severa
        },
        "normal": {
            "perfect": lambda corr: 0.7 <= corr <= 0.95,
            "pass": lambda corr: (0.5 <= corr < 0.7) or (0.95 < corr <= 1.0),
            "warning": lambda corr: (0.3 <= corr < 0.5) or (-0.2 < corr <= 0.3),
            "critical": lambda corr: -0.5 <= corr <= -0.2,
            "catastrophic": lambda corr: corr < -0.5,  # Antifase severa
        }
    }

    SCORES = {
        "catastrophic": -2.0,  # Nuevo: casos extremos
        "critical": -1.0,
        "warning": 0.0,
        "pass": 0.7,
        "perfect": 1.0,
        "conservative": 0.4,
    }


def calculate_headroom_score(peak_db: float, strict: bool) -> Tuple[str, float]:
    """
    Calculate headroom score WITHOUT language dependency.
    Returns: (status, score_delta)
    """
    mode = "strict" if strict else "normal"
    thresholds = ScoringThresholds.HEADROOM[mode]
    
    if thresholds["critical"](peak_db):
        return "critical", ScoringThresholds.SCORES["critical"]
    elif thresholds["warning"](peak_db):
        return "warning", ScoringThresholds.SCORES["warning"]
    elif thresholds["perfect"](peak_db):
        return "perfect", ScoringThresholds.SCORES["perfect"]
    elif thresholds["pass"](peak_db):
        return "pass", ScoringThresholds.SCORES["pass"]
    elif thresholds["conservative"](peak_db):
        return "conservative", ScoringThresholds.SCORES["conservative"]
    else:
        return "pass", ScoringThresholds.SCORES["conservative"]


def calculate_true_peak_score(tp_db: float, strict: bool) -> Tuple[str, float, bool]:
    """
    Calculate true peak score WITHOUT language dependency.
    Returns: (status, score_delta, hard_fail)
    
    Hard fail SOLO si True Peak >= +3.0 dBTP (clipping intersample extremo).
    Para TP entre -0.5 y +3.0: cr√≠tico pero corregible (NO hard fail).
    """
    mode = "strict" if strict else "normal"
    thresholds = ScoringThresholds.TRUE_PEAK[mode]
    
    # Hard fail solo para casos EXTREMOS (>= +3.0 dBTP)
    if tp_db >= 3.0:
        return "critical", ScoringThresholds.SCORES["critical"], True
    
    # True Peak cr√≠tico pero corregible (< +3.0)
    if thresholds["critical"](tp_db):
        return "critical", ScoringThresholds.SCORES["critical"], False
    elif thresholds["warning"](tp_db):
        return "warning", 0.3 if strict else 0.4, False
    elif thresholds["perfect"](tp_db):
        return "perfect", ScoringThresholds.SCORES["perfect"], False
    else:  # pass
        return "pass", ScoringThresholds.SCORES["pass"], False


def calculate_plr_score(plr_db: float, lufs_reliable: bool, strict: bool) -> Tuple[str, float]:
    """
    Calculate PLR score WITHOUT language dependency.
    Returns: (status, score_delta)
    """
    if not lufs_reliable:
        return "pass", 0.5
    
    mode = "strict" if strict else "normal"
    thresholds = ScoringThresholds.PLR[mode]
    
    if thresholds["perfect"](plr_db):
        return "perfect", ScoringThresholds.SCORES["perfect"]
    elif thresholds["pass"](plr_db):
        return "pass", ScoringThresholds.SCORES["pass"]
    elif thresholds["warning"](plr_db):
        return "warning", 0.3
    else:  # critical
        return "critical", -0.5


def calculate_stereo_score(correlation: float, strict: bool) -> Tuple[str, float]:
    """
    Calculate stereo width score WITHOUT language dependency.
    Returns: (status, score_delta)
    """
    mode = "strict" if strict else "normal"
    thresholds = ScoringThresholds.STEREO_WIDTH[mode]
    
    if thresholds["catastrophic"](correlation):
        return "catastrophic", ScoringThresholds.SCORES["catastrophic"]
    elif thresholds["critical"](correlation):
        return "critical", ScoringThresholds.SCORES["critical"]
    elif thresholds["perfect"](correlation):
        return "perfect", ScoringThresholds.SCORES["perfect"]
    elif thresholds["pass"](correlation):
        return "pass", ScoringThresholds.SCORES["pass"]
    else:  # warning
        return "warning", 0.3


# ----------------------------
# TERRITORY & SCORE HELPERS
# ----------------------------

def detect_territory(lufs: Optional[float], peak_db: float, tp_db: float, plr: Optional[float]) -> str:
    """
    Detecta en qu√© 'territorio' est√° el archivo:
    - 'mix': Niveles normales de mezcla para mastering
    - 'hot_mix': Mezcla caliente pero no m√°ster
    - 'master_territory': Niveles de m√°ster finalizado
    
    Esto ayuda a contextualizar las recomendaciones.
    """
    # Master territory - niveles comerciales
    if lufs is not None and lufs > -14.5:
        if peak_db > -1.0 or tp_db > -1.0:
            return "master_territory"
    
    # True peak positivo = casi siempre un m√°ster
    if tp_db > -0.5:
        return "master_territory"
    
    # Hot mix - m√°s alto que el t√≠pico pero no m√°ster
    if lufs is not None and lufs > -16.0:
        if peak_db > -2.0:
            return "hot_mix"
    
    # Normal mix
    return "mix"


def detect_mastered_file(
    lufs: Optional[float], 
    peak_db: float, 
    tp_db: float, 
    plr: Optional[float],
    tp_clipping_pct: float
) -> Dict[str, Any]:
    """
    Detecta si el archivo es un master finalizado en vez de una mezcla.
    
    Criterios:
    - True Peak > 0 dBTP Y Headroom < 0.5 dB
    - LUFS > -12 (nivel comercial)
    - PLR < 7 dB (muy comprimido)
    - True Peak clipping > 50% del track
    
    Returns: {
        "is_mastered": bool,
        "confidence": str,  # "high", "medium", "low"
        "indicators": List[str]
    }
    """
    indicators = []
    
    # Indicador 1: True peak over ceiling
    if tp_db > 0.0:
        indicators.append("true_peak_over_ceiling")
    
    # Indicador 2: Headroom cr√≠tico
    if peak_db >= -0.5:
        indicators.append("critical_headroom")
    
    # Indicador 3: Loudness comercial
    if lufs is not None and lufs > -12.0:
        indicators.append("commercial_loudness")
    
    # Indicador 4: Over-compression
    if plr is not None and plr < 7.0:
        indicators.append("heavy_limiting")
    
    # Indicador 5: Clipping sostenido
    if tp_clipping_pct > 50:
        indicators.append("sustained_clipping")
    
    # Determinar si es master y confianza
    indicator_count = len(indicators)
    
    if indicator_count >= 3:
        confidence = "high"
        is_mastered = True
    elif indicator_count == 2:
        confidence = "medium"
        is_mastered = True
    elif indicator_count == 1 and "true_peak_over_ceiling" in indicators:
        confidence = "medium"
        is_mastered = True
    else:
        confidence = "low"
        is_mastered = False
    
    return {
        "is_mastered": is_mastered,
        "confidence": confidence,
        "indicators": indicators
    }


def calculate_minimum_score(metrics: List[Dict[str, Any]]) -> int:
    """
    Determina el score m√≠nimo seg√∫n la severidad de los problemas.
    Nunca retorna 0 - siempre hay algo rescatable en un archivo de audio.
    
    Filosof√≠a: Incluso archivos con problemas graves tienen valor y pueden
    ser corregidos. Un score de 0 implica "completamente in√∫til", lo cual
    rara vez es cierto en producci√≥n musical.
    """
    catastrophic_count = sum(1 for m in metrics if m.get("status") == "catastrophic")
    critical_count = sum(1 for m in metrics if m.get("status") == "critical")
    
    if catastrophic_count >= 2:
        return 10  # M√∫ltiples problemas catastr√≥ficos (ej: fase invertida + clipping extremo)
    elif catastrophic_count == 1:
        return 15  # Un problema catastr√≥fico (ej: solo fase invertida severa)
    elif critical_count >= 3:
        return 20  # M√∫ltiples cr√≠ticos (ej: headroom + true peak + PLR)
    elif critical_count >= 2:
        return 25  # Dos cr√≠ticos (ej: headroom + true peak)
    elif critical_count == 1:
        return 35  # Un cr√≠tico (ej: solo true peak alto - caso com√∫n)
    else:
        return 50  # Solo warnings o mejor


# ----------------------------
# Audio utilities
# ----------------------------
def peak_dbfs(y: np.ndarray) -> float:
    """Pico sample en dBFS (0 dBFS = 1.0)."""
    peak = float(np.max(np.abs(y))) if y.size else 0.0
    peak = max(peak, 1e-12)
    return 20.0 * math.log10(peak)


def detect_dc_offset(y: np.ndarray) -> Dict[str, Any]:
    """Detect DC offset per channel."""
    offsets = []
    has_issue = False
    
    for ch in range(y.shape[0]):
        offset = float(np.mean(y[ch]))
        offsets.append(offset)
        if abs(offset) > DC_OFFSET_THRESHOLD:
            has_issue = True
    
    return {
        "detected": has_issue,
        "offsets": offsets,
        "max_offset": float(max(abs(o) for o in offsets))
    }


def calculate_crest_factor(y: np.ndarray) -> float:
    """
    Compute crest factor (peak-to-RMS ratio) en dB.
    √ötil cuando pyloudnorm no est√° disponible.
    
    Para est√©reo, usa el peak m√°ximo de ambos canales y RMS combinado
    (consistente con c√≥mo se mide PLR y LUFS).
    """
    if y.shape[0] > 1:
        # Stereo: max peak from both channels
        peak = float(np.max(np.abs(y)))
        # RMS combined from both channels
        rms_l = float(np.sqrt(np.mean(y[0].astype(np.float64) ** 2)))
        rms_r = float(np.sqrt(np.mean(y[1].astype(np.float64) ** 2)))
        rms = float(np.sqrt((rms_l**2 + rms_r**2) / 2))
    else:
        # Mono
        audio = y[0]
        peak = float(np.max(np.abs(audio))) if audio.size else 1e-12
        rms = float(np.sqrt(np.mean(audio.astype(np.float64) ** 2))) if audio.size else 1e-12
    
    peak = max(peak, 1e-12)
    rms = max(rms, 1e-12)
    
    return 20.0 * math.log10(peak / rms)


def auto_oversample_factor(sr: int) -> int:
    """
    Determine optimal oversampling factor based on sample rate.
    
    - 44.1/48 kHz: 4x (est√°ndar)
    - 88.2/96 kHz: 2x (ya est√°n sobremuestreados)
    - 176.4/192 kHz+: 1x (no necesario)
    """
    if sr >= 176400:
        return 1
    elif sr >= 88200:
        return 2
    else:
        return 4


def oversampled_true_peak_db(y: np.ndarray, os_factor: int = 4) -> float:
    """True peak aproximado: sobremuestreo por resample_poly y pico en dBFS."""
    if os_factor <= 1:
        return peak_dbfs(y)
    
    peaks = []
    for ch in range(y.shape[0]):
        up = resample_poly(y[ch], up=os_factor, down=1)
        peaks.append(float(np.max(np.abs(up))) if up.size else 0.0)
    
    tp = max(max(peaks), 1e-12)
    return 20.0 * math.log10(tp)


def integrated_lufs(y: np.ndarray, sr: int, duration: float) -> Tuple[Optional[float], str, bool]:
    """
    LUFS integrado real (EBU R128) si pyloudnorm est√° instalado.
    Retorna (lufs, method, is_reliable).
    
    IMPORTANTE: Calcula LUFS con audio est√©reo completo (no mono).
    """
    is_reliable = duration >= MIN_DURATION_FOR_LUFS
    
    if HAS_PYLOUDNORM:
        try:
            meter = pyln.Meter(sr)
            
            # FIXED: Pass stereo audio correctly
            # pyloudnorm expects shape (samples, channels) not (channels, samples)
            if y.shape[0] > 1:
                # Stereo: transpose from (channels, samples) to (samples, channels)
                audio = y.T
            else:
                # Mono: reshape from (1, samples) to (samples,)
                audio = y[0]
            
            lufs = float(meter.integrated_loudness(audio.astype(np.float64)))
            
            # pyloudnorm retorna -inf para se√±ales muy bajas
            if not np.isfinite(lufs):
                return None, "pyloudnorm/EBU-R128", is_reliable
            
            return lufs, "pyloudnorm/EBU-R128", is_reliable
        except Exception as e:
            print(f"‚ö†Ô∏è  Error calculando LUFS: {e}", file=sys.stderr)
            return None, "error", False
    
    # fallback: RMS dBFS approx (solo informativo)
    # For stereo, calculate RMS of each channel and combine (like LUFS does)
    if y.shape[0] > 1:
        # Stereo: RMS of both channels combined
        rms_l = float(np.sqrt(np.mean(y[0].astype(np.float64) ** 2)))
        rms_r = float(np.sqrt(np.mean(y[1].astype(np.float64) ** 2)))
        # Combine as energy sum (like LUFS does for multichannel)
        rms = float(np.sqrt((rms_l**2 + rms_r**2) / 2))
    else:
        # Mono
        rms = float(np.sqrt(np.mean(y[0].astype(np.float64) ** 2)))
    
    rms = max(rms, 1e-12)
    return 20.0 * math.log10(rms), "approx_rms_dbfs", is_reliable


def stereo_correlation(y: np.ndarray) -> float:
    """Correlaci√≥n L/R en [-1, 1]. Si es mono, retorna 1.0."""
    if y.shape[0] < 2:
        return 1.0
    
    L = y[0].astype(np.float64)
    R = y[1].astype(np.float64)
    n = min(L.size, R.size)
    
    if n < 2:
        return 1.0
    
    L = L[:n] - np.mean(L[:n])
    R = R[:n] - np.mean(R[:n])
    denom = (np.std(L) * np.std(R)) + 1e-12
    
    return float(np.mean(L * R) / denom)


def calculate_ms_ratio(y: np.ndarray) -> Tuple[float, float, float]:
    """
    Calculate Mid/Side ratio and related metrics.
    Returns: (ms_ratio, mid_rms, side_rms)
    
    M/S Ratio indica el balance entre informaci√≥n central (mid) y panoramizada (side).
    Valores t√≠picos: 0.3-0.7 para mezclas saludables
    """
    if y.shape[0] < 2:
        return 0.0, 0.0, 0.0
    
    L, R = y[0], y[1]
    mid = (L + R) / 2
    side = (L - R) / 2
    
    mid_rms = float(np.sqrt(np.mean(mid**2)))
    side_rms = float(np.sqrt(np.mean(side**2)))
    
    # Avoid division by zero
    ms_ratio = side_rms / (mid_rms + 1e-12) if mid_rms > 1e-9 else 0.0
    
    return ms_ratio, mid_rms, side_rms


def calculate_lr_balance(y: np.ndarray) -> float:
    """
    Calculate L/R energy balance in dB.
    Returns: dB difference (positive = more left, negative = more right)
    
    Balance L/R indica si hay m√°s energ√≠a en un canal que en otro.
    Ideal: ¬±1 dB, Aceptable: ¬±3 dB
    """
    if y.shape[0] < 2:
        return 0.0
    
    L_rms = float(np.sqrt(np.mean(y[0]**2)))
    R_rms = float(np.sqrt(np.mean(y[1]**2)))
    
    if L_rms < 1e-9 or R_rms < 1e-9:
        return 0.0
    
    # Positive = more left, negative = more right
    return 20 * np.log10(L_rms / R_rms)


# ----------------------------
# TEMPORAL ANALYSIS FUNCTIONS
# ----------------------------

def format_timestamp(seconds: float) -> str:
    """Convert seconds to MM:SS format."""
    minutes = int(seconds // 60)
    secs = int(seconds % 60)
    return f"{minutes}:{secs:02d}"


def format_temporal_message(temporal_data: Dict[str, Any], parameter_name: str, lang: str = 'en') -> str:
    """
    Format temporal analysis data into human-readable message.
    Returns additional message to append to base message.
    """
    if not temporal_data or temporal_data.get("severity") == "none":
        return ""
    
    severity = temporal_data.get("severity")
    affected_pct = temporal_data.get("affected_percentage", 0)
    problem_moments = temporal_data.get("problem_moments", [])
    total_occurrences = temporal_data.get("total_occurrences", 0)
    
    lang = _pick_lang(lang)
    
    if severity == "widespread":
        if lang == 'es':
            return f"\n\n‚è±Ô∏è Temporal: Presente durante la mayor parte del track ({affected_pct:.0f}% del tiempo)."
        else:
            return f"\n\n‚è±Ô∏è Temporal: Present throughout most of the track ({affected_pct:.0f}% of the time)."
    
    elif severity == "localized" and problem_moments:
        # Format timestamps
        timestamps_str = ", ".join([m["time"] for m in problem_moments[:5]])
        
        if total_occurrences > 5:
            if lang == 'es':
                timestamps_str += f" (y {total_occurrences - 5} m√°s)"
            else:
                timestamps_str += f" (and {total_occurrences - 5} more)"
        
        if lang == 'es':
            return f"\n\n‚è±Ô∏è Temporal: Detectado en {total_occurrences} momento(s) espec√≠fico(s): {timestamps_str}."
        else:
            return f"\n\n‚è±Ô∏è Temporal: Detected in {total_occurrences} specific moment(s): {timestamps_str}."
    
    return ""


def analyze_true_peak_temporal(y: np.ndarray, sr: int, oversample: int = 4, threshold: float = 0.0) -> Dict[str, Any]:
    """
    Temporal analysis of true peak.
    Detects REGIONS where true peak exceeds threshold (not just individual moments).
    
    Returns:
    - severity: "localized" or "widespread"
    - affected_percentage: % of track with issue
    - problem_regions: list of (start, end) timestamp pairs
    - max_value: maximum true peak found
    """
    # Calculate true peak for entire track
    tp = oversampled_true_peak_db(y, os_factor=oversample)
    
    # Window-based analysis (5 second windows)
    window_duration = 5.0  # seconds
    window_samples = int(window_duration * sr)
    hop_samples = window_samples // 2  # 50% overlap
    
    problem_windows = []
    total_windows = 0
    
    for start in range(0, y.shape[1] - window_samples, hop_samples):
        end = start + window_samples
        window = y[:, start:end]
        
        window_tp = oversampled_true_peak_db(window, os_factor=oversample)
        total_windows += 1
        
        timestamp = start / sr
        
        if window_tp > threshold:
            problem_windows.append({
                "time_seconds": timestamp,
                "value": round(window_tp, 1)
            })
    
    # Now detect CONTINUOUS REGIONS from problem windows
    problem_regions = []
    
    if problem_windows:
        current_region_start = problem_windows[0]["time_seconds"]
        current_region_end = problem_windows[0]["time_seconds"]
        
        for i in range(1, len(problem_windows)):
            prev_time = problem_windows[i-1]["time_seconds"]
            curr_time = problem_windows[i]["time_seconds"]
            
            # If gap is less than 10 seconds, consider it same region
            if curr_time - prev_time <= 10.0:
                current_region_end = curr_time
            else:
                # Save previous region and start new one
                problem_regions.append({
                    "start": format_timestamp(current_region_start),
                    "end": format_timestamp(current_region_end),
                    "start_seconds": current_region_start,
                    "end_seconds": current_region_end
                })
                current_region_start = curr_time
                current_region_end = curr_time
        
        # Don't forget the last region
        problem_regions.append({
            "start": format_timestamp(current_region_start),
            "end": format_timestamp(current_region_end),
            "start_seconds": current_region_start,
            "end_seconds": current_region_end
        })
    
    affected_percentage = (len(problem_windows) / total_windows * 100) if total_windows > 0 else 0
    severity = "widespread" if affected_percentage >= 20 else "localized"
    
    return {
        "severity": severity,
        "affected_percentage": round(affected_percentage, 1),
        "problem_regions": problem_regions,  # Now returns REGIONS not moments
        "total_regions": len(problem_regions),
        "max_value": round(tp, 1)
    }


def analyze_clipping_temporal(y: np.ndarray, sr: int, threshold: float = 0.999999) -> Dict[str, Any]:
    """
    Temporal analysis of clipping.
    Detects REGIONS where samples clip (not just individual moments).
    """
    # Find clipped samples
    clipped_samples = np.where(np.abs(y) >= threshold)[1]
    
    if len(clipped_samples) == 0:
        return {
            "severity": "none",
            "affected_percentage": 0.0,
            "problem_regions": [],
            "total_regions": 0
        }
    
    # Group clipped samples into moments (within 0.1s of each other)
    problem_moments = []
    last_time = -999
    
    for sample_idx in clipped_samples:
        time_seconds = sample_idx / sr
        
        # Only add if it's a new moment (>0.1s from last)
        if time_seconds - last_time > 0.1:
            problem_moments.append({"time_seconds": time_seconds})
            last_time = time_seconds
    
    # Now detect CONTINUOUS REGIONS from problem moments
    problem_regions = []
    
    if problem_moments:
        current_region_start = problem_moments[0]["time_seconds"]
        current_region_end = problem_moments[0]["time_seconds"]
        
        for i in range(1, len(problem_moments)):
            prev_time = problem_moments[i-1]["time_seconds"]
            curr_time = problem_moments[i]["time_seconds"]
            
            # If gap is less than 5 seconds, consider it same region (shorter for clipping)
            if curr_time - prev_time <= 5.0:
                current_region_end = curr_time
            else:
                # Save previous region and start new one
                problem_regions.append({
                    "start": format_timestamp(current_region_start),
                    "end": format_timestamp(current_region_end),
                    "start_seconds": current_region_start,
                    "end_seconds": current_region_end
                })
                current_region_start = curr_time
                current_region_end = curr_time
        
        # Don't forget the last region
        problem_regions.append({
            "start": format_timestamp(current_region_start),
            "end": format_timestamp(current_region_end),
            "start_seconds": current_region_start,
            "end_seconds": current_region_end
        })
    
    total_samples = y.shape[1]
    affected_percentage = (len(clipped_samples) / total_samples * 100)
    severity = "widespread" if affected_percentage >= 1.0 else "localized"
    
    return {
        "severity": severity,
        "affected_percentage": round(affected_percentage, 3),
        "problem_regions": problem_regions,
        "total_regions": len(problem_regions)
    }


def analyze_correlation_temporal(y: np.ndarray, sr: int, threshold: float = 0.3) -> Dict[str, Any]:
    """
    Temporal analysis of stereo correlation.
    Detects REGIONS where correlation is problematic (not just individual moments).
    """
    if y.shape[0] < 2:
        return {"severity": "none", "affected_percentage": 0.0, "problem_regions": [], "total_regions": 0}
    
    # Window-based analysis (5 second windows)
    window_duration = 5.0
    window_samples = int(window_duration * sr)
    hop_samples = window_samples // 2
    
    problem_windows = []
    total_windows = 0
    min_corr = 1.0
    
    for start in range(0, y.shape[1] - window_samples, hop_samples):
        end = start + window_samples
        window = y[:, start:end]
        
        corr = stereo_correlation(window)
        total_windows += 1
        
        if corr < min_corr:
            min_corr = corr
        
        timestamp = start / sr
        
        if corr < threshold:
            problem_windows.append({
                "time_seconds": timestamp,
                "value": round(corr * 100, 0)
            })
    
    # Now detect CONTINUOUS REGIONS from problem windows
    problem_regions = []
    
    if problem_windows:
        current_region_start = problem_windows[0]["time_seconds"]
        current_region_end = problem_windows[0]["time_seconds"]
        
        for i in range(1, len(problem_windows)):
            prev_time = problem_windows[i-1]["time_seconds"]
            curr_time = problem_windows[i]["time_seconds"]
            
            # If gap is less than 10 seconds, consider it same region
            if curr_time - prev_time <= 10.0:
                current_region_end = curr_time
            else:
                # Save previous region and start new one
                problem_regions.append({
                    "start": format_timestamp(current_region_start),
                    "end": format_timestamp(current_region_end),
                    "start_seconds": current_region_start,
                    "end_seconds": current_region_end
                })
                current_region_start = curr_time
                current_region_end = curr_time
        
        # Don't forget the last region
        problem_regions.append({
            "start": format_timestamp(current_region_start),
            "end": format_timestamp(current_region_end),
            "start_seconds": current_region_start,
            "end_seconds": current_region_end
        })
    
    affected_percentage = (len(problem_windows) / total_windows * 100) if total_windows > 0 else 0
    severity = "widespread" if affected_percentage >= 20 else "localized"
    
    return {
        "severity": severity,
        "affected_percentage": round(affected_percentage, 1),
        "problem_regions": problem_regions,
        "total_regions": len(problem_regions),
        "min_value": round(min_corr * 100, 0)
    }


def analyze_lr_balance_temporal(y: np.ndarray, sr: int, threshold: float = 3.0) -> Dict[str, Any]:
    """
    Temporal analysis of L/R balance.
    Detects REGIONS where balance exceeds threshold (not just individual moments).
    """
    if y.shape[0] < 2:
        return {"severity": "none", "affected_percentage": 0.0, "problem_regions": [], "total_regions": 0}
    
    # Window-based analysis (5 second windows)
    window_duration = 5.0
    window_samples = int(window_duration * sr)
    hop_samples = window_samples // 2
    
    problem_windows = []
    total_windows = 0
    max_imbalance = 0.0
    
    for start in range(0, y.shape[1] - window_samples, hop_samples):
        end = start + window_samples
        window = y[:, start:end]
        
        balance = calculate_lr_balance(window)
        total_windows += 1
        
        if abs(balance) > abs(max_imbalance):
            max_imbalance = balance
        
        timestamp = start / sr
        
        if abs(balance) > threshold:
            problem_windows.append({
                "time_seconds": timestamp,
                "value": round(balance, 1)
            })
    
    # Now detect CONTINUOUS REGIONS from problem windows
    problem_regions = []
    
    if problem_windows:
        current_region_start = problem_windows[0]["time_seconds"]
        current_region_end = problem_windows[0]["time_seconds"]
        
        for i in range(1, len(problem_windows)):
            prev_time = problem_windows[i-1]["time_seconds"]
            curr_time = problem_windows[i]["time_seconds"]
            
            # If gap is less than 10 seconds, consider it same region
            if curr_time - prev_time <= 10.0:
                current_region_end = curr_time
            else:
                # Save previous region and start new one
                problem_regions.append({
                    "start": format_timestamp(current_region_start),
                    "end": format_timestamp(current_region_end),
                    "start_seconds": current_region_start,
                    "end_seconds": current_region_end
                })
                current_region_start = curr_time
                current_region_end = curr_time
        
        # Don't forget the last region
        problem_regions.append({
            "start": format_timestamp(current_region_start),
            "end": format_timestamp(current_region_end),
            "start_seconds": current_region_start,
            "end_seconds": current_region_end
        })
    
    affected_percentage = (len(problem_windows) / total_windows * 100) if total_windows > 0 else 0
    severity = "widespread" if affected_percentage >= 20 else "localized"
    
    return {
        "severity": severity,
        "affected_percentage": round(affected_percentage, 1),
        "problem_regions": problem_regions,
        "total_regions": len(problem_regions),
        "max_imbalance": round(max_imbalance, 1)
    }


def analyze_ms_ratio_temporal(y: np.ndarray, sr: int, low_threshold: float = 0.05, high_threshold: float = 1.5) -> Dict[str, Any]:
    """
    Temporal analysis of M/S ratio.
    Detects REGIONS where M/S ratio is problematic (too low or too high).
    """
    if y.shape[0] < 2:
        return {"severity": "none", "affected_percentage": 0.0, "problem_regions": [], "total_regions": 0}
    
    # Window-based analysis (5 second windows)
    window_duration = 5.0
    window_samples = int(window_duration * sr)
    hop_samples = window_samples // 2
    
    problem_windows = []
    total_windows = 0
    min_ms = 999.0
    max_ms = 0.0
    
    for start in range(0, y.shape[1] - window_samples, hop_samples):
        end = start + window_samples
        window = y[:, start:end]
        
        ms_ratio, _, _ = calculate_ms_ratio(window)
        total_windows += 1
        
        if ms_ratio < min_ms:
            min_ms = ms_ratio
        if ms_ratio > max_ms:
            max_ms = ms_ratio
        
        is_problem = ms_ratio < low_threshold or ms_ratio > high_threshold
        
        timestamp = start / sr
        
        if is_problem:
            problem_type = "mono" if ms_ratio < low_threshold else "too_wide"
            problem_windows.append({
                "time_seconds": timestamp,
                "value": round(ms_ratio, 2),
                "type": problem_type
            })
    
    # Now detect CONTINUOUS REGIONS from problem windows
    problem_regions = []
    
    if problem_windows:
        current_region_start = problem_windows[0]["time_seconds"]
        current_region_end = problem_windows[0]["time_seconds"]
        
        for i in range(1, len(problem_windows)):
            prev_time = problem_windows[i-1]["time_seconds"]
            curr_time = problem_windows[i]["time_seconds"]
            
            # If gap is less than 10 seconds, consider it same region
            if curr_time - prev_time <= 10.0:
                current_region_end = curr_time
            else:
                # Save previous region and start new one
                problem_regions.append({
                    "start": format_timestamp(current_region_start),
                    "end": format_timestamp(current_region_end),
                    "start_seconds": current_region_start,
                    "end_seconds": current_region_end
                })
                current_region_start = curr_time
                current_region_end = curr_time
        
        # Don't forget the last region
        problem_regions.append({
            "start": format_timestamp(current_region_start),
            "end": format_timestamp(current_region_end),
            "start_seconds": current_region_start,
            "end_seconds": current_region_end
        })
    
    affected_percentage = (len(problem_windows) / total_windows * 100) if total_windows > 0 else 0
    severity = "widespread" if affected_percentage >= 20 else "localized"
    
    return {
        "severity": severity,
        "affected_percentage": round(affected_percentage, 1),
        "problem_regions": problem_regions,
        "total_regions": len(problem_regions),
        "min_ms": round(min_ms, 2),
        "max_ms": round(max_ms, 2)
    }


def evaluate_stereo_field_comprehensive(corr: float, ms_ratio: float, lr_balance: float, lang: str = 'en', strict: bool = False) -> Tuple[str, str]:
    """
    Comprehensive stereo field evaluation considering:
    - Correlation (phase relationship)
    - M/S Ratio (stereo width)
    - L/R Balance (channel balance)
    
    Returns enhanced message with contextual information.
    In strict mode, adds commercial delivery standards.
    """
    lang = _pick_lang(lang)
    
    # Get base correlation status and message
    base_status, base_message, _ = _status_stereo_en(corr) if lang == 'en' else _status_stereo_es(corr)
    
    # Build additional context
    context_parts = []
    
    # Check M/S Ratio
    if ms_ratio < 0.05:
        if lang == 'es':
            context_parts.append("‚ö†Ô∏è La mezcla no tiene informaci√≥n est√©reo (pr√°cticamente mono). ¬øEs intencional? Verifica si exportaste en mono por error.")
        else:
            context_parts.append("‚ö†Ô∏è Mix has no stereo information (practically mono). Is this intentional? Check if you exported in mono by mistake.")
    elif ms_ratio > 1.5:
        if lang == 'es':
            context_parts.append(f"‚ö†Ô∏è Est√©reo muy ancho (M/S: {ms_ratio:.2f}). Puede sonar d√©bil en parlantes o mono. Considera reducir stereo widening.")
        else:
            context_parts.append(f"‚ö†Ô∏è Very wide stereo (M/S: {ms_ratio:.2f}). May sound weak on speakers or mono. Consider reducing stereo widening.")
    
    # Check L/R Balance
    if abs(lr_balance) > 3.0:
        side = "izquierdo" if lr_balance > 0 else "derecho" if lang == 'es' else "left" if lr_balance > 0 else "right"
        if lang == 'es':
            context_parts.append(f"‚ö†Ô∏è Desbalance L/R: {abs(lr_balance):.1f} dB m√°s energ√≠a en canal {side}. Verifica paneo y volumen de canales.")
        else:
            context_parts.append(f"‚ö†Ô∏è L/R imbalance: {abs(lr_balance):.1f} dB more energy in {side} channel. Check panning and channel volumes.")
    
    # Combine base message with context
    if context_parts:
        enhanced_message = base_message + "\n\n" + "\n".join(context_parts)
    else:
        # Add M/S and LR info - with commercial standards in strict mode
        if strict:
            if lang == 'es':
                enhanced_message = (base_message + 
                    f" M/S Ratio: {ms_ratio:.2f} (rango comercial: 0.3-0.7), "
                    f"Balance L/R: {lr_balance:+.1f} dB (tolerancia profesional: ¬±3 dB).")
            else:
                enhanced_message = (base_message + 
                    f" M/S Ratio: {ms_ratio:.2f} (commercial range: 0.3-0.7), "
                    f"L/R Balance: {lr_balance:+.1f} dB (professional tolerance: ¬±3 dB).")
        else:
            if lang == 'es':
                enhanced_message = base_message + f" M/S Ratio: {ms_ratio:.2f} (balanceado), Balance L/R: {lr_balance:+.1f} dB (centrado)."
            else:
                enhanced_message = base_message + f" M/S Ratio: {ms_ratio:.2f} (balanced), L/R Balance: {lr_balance:+.1f} dB (centered)."
    
    return base_status, enhanced_message


def band_balance_db(y: np.ndarray, sr: int) -> Dict[str, float]:
    """
    Calcula niveles por banda (dB) usando an√°lisis perceptual con K-weighting.
    Tambi√©n calcula porcentajes de energ√≠a por banda para mejor comprensi√≥n.
    
    Usa K-weighting (ITU-R BS.1770) para match con LUFS y percepci√≥n humana.
    
    Para est√©reo, promedia la se√±al temporal (aceptable para an√°lisis espectral).
    Nota: A diferencia de LUFS, para an√°lisis de frecuencias promediar la se√±al
    es una pr√°ctica est√°ndar ya que estamos midiendo contenido espectral, no loudness.
    
    Bandas:
      Low: 20‚Äì250 Hz
      Mid: 250‚Äì4000 Hz
      High: 4000‚Äìmin(20000, Nyquist) Hz
    """
    audio = y.mean(axis=0) if y.shape[0] > 1 else y[0]
    audio = audio.astype(np.float64)

    # Par√°metros STFT optimizados
    n_fft = 8192  # Mayor resoluci√≥n para bajos
    hop = 2048
    
    S = librosa.stft(audio, n_fft=n_fft, hop_length=hop, window="hann", center=True)
    freqs = librosa.fft_frequencies(sr=sr, n_fft=n_fft)
    
    # Aplicar K-weighting (ITU-R BS.1770 simplificado)
    #Highpass ~38 Hz + Highshelf ~1.5kHz
    k_weight = np.ones_like(freqs)
    
    # Stage 1: Highpass filter (shelf at ~38 Hz)
    f_hp = 38.0
    for i, f in enumerate(freqs):
        if f > 0:
            # Simplified highpass response
            k_weight[i] *= (f**2) / (f**2 + f_hp**2)
    
    # Stage 2: High-frequency shelf boost (~+4dB at 1.5kHz and above)
    f_shelf = 1500.0
    for i, f in enumerate(freqs):
        if f > 0:
            # Simplified high shelf
            shelf_gain = 1.0 + 0.58 * (f**2) / (f**2 + f_shelf**2)  # ~+4dB boost
            k_weight[i] *= shelf_gain
    
    # Calcular magnitud con K-weighting aplicado
    magnitude = np.abs(S) * k_weight[:, np.newaxis]
    
    # Usar percentil 75 en vez de mean para mejor representaci√≥n
    # Esto evita que bass sostenido domine sobre transientes
    P = np.percentile(magnitude**2, 75, axis=1)  # 75th percentile de potencia
    
    nyq = sr / 2.0
    hi_max = min(20000.0, nyq)

    def band_power(f_lo: float, f_hi: float) -> float:
        idx = np.where((freqs >= f_lo) & (freqs < f_hi))[0]
        if idx.size == 0:
            return 1e-12
        # Integrar potencia ponderada
        return float(np.sum(P[idx]) + 1e-12)

    low_p = band_power(20.0, 250.0)
    mid_p = band_power(250.0, 4000.0)
    high_p = band_power(4000.0, hi_max)

    low_db = 10.0 * math.log10(low_p)
    mid_db = 10.0 * math.log10(mid_p)
    high_db = 10.0 * math.log10(high_p)
    
    # Calculate percentages for easier understanding
    total_energy = low_p + mid_p + high_p
    if total_energy > 0:
        low_percent = (low_p / total_energy) * 100.0
        mid_percent = (mid_p / total_energy) * 100.0
        high_percent = (high_p / total_energy) * 100.0
    else:
        low_percent = mid_percent = high_percent = 0.0

    return {
        "low_db": low_db,
        "mid_db": mid_db,
        "high_db": high_db,
        "d_low_mid_db": low_db - mid_db,
        "d_high_mid_db": high_db - mid_db,
        "low_percent": low_percent,
        "mid_percent": mid_percent,
        "high_percent": high_percent,
    }


# ----------------------------
# Reglas / estados
# ----------------------------
def _status_headroom_en(peak_db: float, strict: bool = False) -> Tuple[str, str, float]:
    """
    English headroom evaluation using UNIFIED scoring engine.
    Now uses calculate_headroom_score() for language-neutral consistency.
    """
    # TRACK 1: Calculate (language-neutral)
    status, score = calculate_headroom_score(peak_db, strict)
    
    # TRACK 2: Format message (Mat√≠as Voice - English)
    mode = "strict" if strict else "normal"
    
    messages = {
        "critical": "Too little headroom / clipping risk. Use a Gain/Utility plugin AFTER your master bus chain (lower 6-8 dB), then re-export. This preserves your mix balance and plugin sound.",
        "warning": {
            "strict": "Mix is running hot. Lower ~1‚Äì2 dB to leave comfortable headroom.",
            "normal": "Mix is a bit hot. Lower ~1‚Äì2 dB to leave margin.",
        },
        "perfect": {
            "strict": "Ideal headroom for commercial mastering delivery.",
            "normal": f"Headroom of {abs(peak_db):.1f} dB is exactly what I'm looking for - gives me room to work with EQ, compression and limiting without compromising quality.",
        },
        "pass": {
            "strict": "Headroom is acceptable for mastering delivery.",
            "normal": "Headroom is appropriate for mastering.",
        },
        "conservative": "Very conservative level. Not wrong, but you could raise ~1‚Äì3 dB if desired.",
    }
    
    # Select appropriate message
    if status in ["warning", "perfect", "pass"]:
        message = messages[status][mode]
    else:
        message = messages[status]
    
    return status, message, score

def _status_true_peak_en(tp_db: float, strict: bool = False) -> Tuple[str, str, float, bool]:
    """
    English true peak evaluation using UNIFIED scoring engine.
    Now uses calculate_true_peak_score() for language-neutral consistency.
    Returns (status, message, score, hard_fail).
    """
    # TRACK 1: Calculate (language-neutral)
    status, score, hard_fail = calculate_true_peak_score(tp_db, strict)
    
    # TRACK 2: Format message (Mat√≠as Voice - English)
    mode = "strict" if strict else "normal"
    
    messages = {
        "critical": "True peak is dangerously high. It may clip after conversion/encoding. Lower the level and re-export.",
        "warning": {
            "strict": "True peak should be ‚â§ -3.0 dBTP for professional commercial delivery.",
            "normal": "True peak is close to the limit. Streaming codecs (MP3, AAC, Opus) may clip. Better to aim for ‚â§ -1.0 dBTP.",
        },
        "perfect": "True peak is very safe for mastering. No issues converting to formats like MP3, AAC or for streaming.",
        "pass": {
            "strict": "True peak is acceptable, but -2 dBTP or better is ideal for clients/labels.",
            "normal": "True peak is safe for mastering.",
        },
    }
    
    # Select appropriate message
    if status in ["warning", "pass"]:
        message = messages[status][mode]
    else:
        message = messages[status]
    
    return status, message, score, hard_fail

def _status_lufs_en(lufs: Optional[float], method: str, is_reliable: bool) -> Tuple[str, str, float]:
    """Evaluate LUFS with reliability consideration."""
    if lufs is None:
        return "info", "Could not calculate LUFS.", 0.0
    
    if not is_reliable:
        return "info", f"File too short (<{MIN_DURATION_FOR_LUFS}s). LUFS may not be reliable.", 0.3
    
    if method == "approx_rms_dbfs":
        return "pass", "Informational level (approx RMS). Install 'pyloudnorm' for real LUFS.", 0.2
    
    # Real LUFS: for mixes it's informational, not prescriptive
    # Range -15 to -35 LUFS is completely normal for pre-mastering mixes
    if lufs > -10.0:
        return "warning", "Mix is very loud. Possible over-limiting on the bus. Check PLR.", 0.3
    if lufs < -40.0:
        return "info", "Level very low; check for excessive silence or incorrect export.", 0.5
    
    # Everything between -10 and -40 LUFS is valid for mixes
    return "perfect", "Loudness is informational; final level is set during mastering.", 1.0

def _status_plr_en(plr: Optional[float], has_real_lufs: bool, strict: bool = False) -> Tuple[str, str, float]:
    """
    English PLR evaluation using UNIFIED scoring engine.
    Now uses calculate_plr_score() for language-neutral consistency.
    """
    if not has_real_lufs or plr is None:
        return "info", "PLR is available only with real LUFS (install 'pyloudnorm').", 0.0
    
    # TRACK 1: Calculate (language-neutral)
    status, score = calculate_plr_score(plr, has_real_lufs, strict)
    
    # TRACK 2: Format message (Mat√≠as Voice - English)
    mode = "strict" if strict else "normal"
    
    messages = {
        "perfect": {
            "strict": "Excellent PLR: optimal dynamics for commercial delivery.",
            "normal": f"Dynamics are very well preserved (PLR: {plr:.1f} dB). You haven't over-limited on the master bus, which gives me plenty of room to work the final loudness without sacrificing musicality.",
        },
        "pass": {
            "strict": "Good PLR for commercial, but ‚â•14 dB is ideal for maximum flexibility.",
            "normal": "Very good PLR for mastering.",
        },
        "warning": f"The mix may already be quite limited (PLR: {plr:.1f} dB). Check master bus limiters/compressors. If you like their color, keep them but adjust so they don't reduce gain (raise threshold/ceiling). This preserves the character while recovering dynamics.",
        "critical": f"PLR very low ({plr:.1f} dB): over-compressed/limited. Remove limiters or adjust them to pass audio without gain reduction (for color only). Alternatively, use less compression on group buses.",
    }
    
    # Select appropriate message
    if status in ["perfect", "pass"]:
        message = messages[status][mode]
    else:
        message = messages[status]
    
    return status, message, score

def _status_stereo_en(corr: float, strict: bool = False) -> Tuple[str, str, float]:
    """
    English stereo correlation evaluation using UNIFIED scoring engine.
    Now uses calculate_stereo_score() for language-neutral consistency.
    """
    # TRACK 1: Calculate (language-neutral)
    status, score = calculate_stereo_score(corr, strict)
    
    # TRACK 2: Format message (Mat√≠as Voice - English)
    messages = {
        "perfect": "Excellent stereo correlation (mono compatible). The mix will translate well on all playback systems.",
        "pass": "Good stereo correlation. The mix maintains a healthy stereo image with good mono compatibility.",
        "warning": "Stereo correlation shows some phase issues. Check stereo effects, reverbs, and panning. Test in mono to ensure nothing important disappears.",
        "critical": f"Low stereo correlation ({corr:.2f}). Significant phase cancellation risk in mono playback. This can cause instruments or vocals to lose volume or disappear entirely on mono systems (Bluetooth speakers, phones, clubs).",
        "catastrophic": f"SEVERE: Near-total phase inversion detected ({corr:.2f}). The mix will almost completely cancel out in mono. Check for: inverted phase plugins, M/S processing errors, or accidentally inverted channels.",
    }
    
    message = messages[status]
    
    return status, message, score

def _status_freq_en(fb: Dict[str, float], genre: Optional[str] = None, strict: bool = False) -> Tuple[str, str, float]:
    """
    Evaluate frequency balance relative to midrange using dB deltas.
    Percentages are informational only (arrangement-dependent).
    
    UNIFIED THRESHOLDS (language-neutral): Match ES for consistency.
    """
    dL = fb["d_low_mid_db"]
    dH = fb["d_high_mid_db"]

    # Normal, wide "mix-for-mastering" ranges (UNIFIED)
    low_perfect = (-6.0, 6.0)
    low_pass = (-9.0, 9.0)
    high_perfect = (-15.0, 10.0)  # UNIFIED: was (-12.0, 6.0)
    high_pass = (-18.0, 12.0)      # UNIFIED: was (-15.0, 9.0)

    # Strict mode: slightly narrower tolerance (commercial delivery)
    if strict:
        low_perfect = (-5.0, 5.0)
        low_pass = (-8.0, 8.0)
        high_perfect = (-12.0, 8.0)   # UNIFIED: was (-11.0, 5.0)
        high_pass = (-15.0, 10.0)     # UNIFIED: was (-14.0, 8.0)

    def in_range(x, r):
        return r[0] <= x <= r[1]

    if in_range(dL, low_perfect) and in_range(dH, high_perfect):
        return "perfect", "Tonal balance is healthy for mastering.", 1.0
    if in_range(dL, low_pass) and in_range(dH, high_pass):
        return "pass", "Tonal balance is generally healthy for mastering.", 0.7

    # Outside pass range: warn, but don't over-penalize (can be artistic)
    msg_parts = []
    if dL > low_pass[1]:
        msg_parts.append("Low end is heavy vs mids")
    elif dL < low_pass[0]:
        msg_parts.append("Low end is light vs mids")
    if dH > high_pass[1]:
        msg_parts.append("High end is bright vs mids")
    elif dH < high_pass[0]:
        msg_parts.append("High end is dark vs mids")

    msg = "Tonal balance shows some character; check translation across systems. (" + ", ".join(msg_parts) + ")." if msg_parts else "Tonal balance shows some character; check translation across systems."
    return "warning", msg, 0.4

def _status_crest_factor_en(crest: float) -> Tuple[str, str, float]:
    """Evaluate crest factor when LUFS is not available."""
    if crest >= 18.0:
        return "perfect", "Excellent dynamics preserved (high crest factor).", 1.0
    if crest >= 14.0:
        return "pass", "Good dynamics for mastering.", 0.7
    if crest >= 10.0:
        return "warning", "Dynamics somewhat compressed. Check bus compression.", 0.4
    return "critical", "Dynamics very compressed/limited. Reduce master bus processing.", -0.5

def _status_dc_offset_en(dc_data: Dict[str, Any]) -> Tuple[str, str, float]:
    """Evaluate DC offset."""
    if not dc_data["detected"]:
        return "perfect", "No DC offset detected.", 1.0
    
    max_offset = dc_data["max_offset"]
    if max_offset > 0.05:
        return "warning", f"Significant DC offset ({max_offset:.3f}). Apply DC offset removal before exporting.", 0.3
    return "pass", f"Minor DC offset detected ({max_offset:.3f}). Consider cleaning.", 0.6


# ----------------------------
# Scoring / reporte
# ----------------------------
WEIGHTS = {
    "Headroom": 0.35,              # Cr√≠tico - aumentado
    "True Peak": 0.35,             # Cr√≠tico - aumentado
    "LUFS (Integrated)": 0.0,      # Solo informativo - sin peso
    "PLR": 0.15,                   # Importante - aumentado
    "Crest Factor": 0.0,           # Redundante con PLR - sin peso cuando hay PLR
    "Stereo Width": 0.10,         # Importante pero no cr√≠tico
    "Frequency Balance": 0.05, # Informativo - reducido
    "DC Offset": 0.0,              # Auto-cr√≠tico si detectado, no suma
}



def _status_headroom_es(peak_db: float, strict: bool = False) -> Tuple[str, str, float]:
    """
    Evaluaci√≥n de headroom en espa√±ol usando scoring engine UNIFICADO.
    Ahora usa calculate_headroom_score() para consistencia language-neutral.
    """
    # TRACK 1: Calcular (language-neutral)
    status, score = calculate_headroom_score(peak_db, strict)
    
    # TRACK 2: Formatear mensaje (Mat√≠as Voice - del eBook)
    mode = "strict" if strict else "normal"
    
    messages = {
        "critical": "Muy poco headroom / riesgo de clipping. Usa un plugin de Gain/Utility DESPU√âS de tu cadena del master bus (b√°jalo 6-8 dB), luego re-exporta. Esto preserva el balance de tu mezcla y el sonido de tus plugins.",
        "warning": {
            "strict": "Headroom insuficiente para entrega comercial. Ideal: -6 a -4 dBFS.",
            "normal": "La mezcla est√° algo caliente. Baja 1‚Äì2 dB para dejar margen.",
        },
        "perfect": {
            "strict": "Headroom perfecto para entrega comercial profesional.",
            "normal": f"El headroom de {abs(peak_db):.1f} dB es exactamente lo que busco - me da espacio para trabajar EQ, compresi√≥n y limiting sin comprometer la calidad.",
        },
        "pass": {
            "strict": "Headroom aceptable, pero -6 a -4 dBFS es ideal para clientes/labels.",
            "normal": "Headroom adecuado para mastering.",
        },
        "conservative": "Nivel muy conservador. No es un problema, pero podr√≠as subir 1‚Äì3 dB si lo deseas.",
    }
    
    # Seleccionar mensaje apropiado
    if status in ["warning", "perfect", "pass"]:
        message = messages[status][mode]
    else:
        message = messages[status]
    
    return status, message, score

def _status_true_peak_es(tp_db: float, strict: bool = False) -> Tuple[str, str, float, bool]:
    """
    Evaluaci√≥n de true peak en espa√±ol usando scoring engine UNIFICADO.
    Ahora usa calculate_true_peak_score() para consistencia language-neutral.
    Retorna (status, message, score, hard_fail).
    """
    # TRACK 1: Calcular (language-neutral)
    status, score, hard_fail = calculate_true_peak_score(tp_db, strict)
    
    # TRACK 2: Formatear mensaje (Mat√≠as Voice - del eBook)
    mode = "strict" if strict else "normal"
    
    messages = {
        "critical": "True peak demasiado alto. Puede distorsionar al convertir/streaming. Baja el nivel y re-exporta.",
        "warning": {
            "strict": "True peak debe ser ‚â§ -3.0 dBTP para entrega comercial profesional.",
            "normal": "True peak muy cerca del l√≠mite. Los codecs de streaming (MP3, AAC, Opus) pueden clipear. Mejor apuntar a ‚â§ -1.0 dBTP.",
        },
        "perfect": "True peak muy seguro para mastering. No habr√° problemas al convertir a formatos como MP3, AAC o para streaming.",
        "pass": {
            "strict": "True peak aceptable, pero -2 dBTP o menos es ideal para clientes/labels.",
            "normal": "True peak seguro para mastering.",
        },
    }
    
    # Seleccionar mensaje apropiado
    if status in ["warning", "pass"]:
        message = messages[status][mode]
    else:
        message = messages[status]
    
    return status, message, score, hard_fail

def _status_lufs_es(lufs: Optional[float], method: str, is_reliable: bool) -> Tuple[str, str, float]:
    """Eval√∫a LUFS con consideraci√≥n de confiabilidad."""
    if lufs is None:
        return "info", "No se pudo calcular LUFS.", 0.0
    
    if not is_reliable:
        return "info", f"Archivo muy corto (<{MIN_DURATION_FOR_LUFS}s). LUFS puede no ser confiable.", 0.3
    
    if method == "approx_rms_dbfs":
        return "pass", "Nivel informativo (RMS aprox). Instala 'pyloudnorm' para LUFS real.", 0.2
    
    # LUFS real: en mezclas es informativo, no prescriptivo
    # Rango -15 a -35 LUFS es completamente normal para mezclas pre-mastering
    if lufs > -10.0:
        return "warning", "Mezcla muy fuerte. Probable over-limitaci√≥n en el bus. Verifica PLR.", 0.3
    if lufs < -40.0:
        return "info", "Nivel muy bajo; revisa si hay silencio excesivo o exportaci√≥n incorrecta.", 0.5
    
    # Todo entre -10 y -40 LUFS es v√°lido para mezclas
    return "perfect", "LUFS informativo. El volumen final se ajusta en mastering.", 1.0

def _status_plr_es(plr: Optional[float], has_real_lufs: bool, strict: bool = False) -> Tuple[str, str, float]:
    """
    Evaluaci√≥n de PLR en espa√±ol usando scoring engine UNIFICADO.
    Ahora usa calculate_plr_score() para consistencia language-neutral.
    """
    if not has_real_lufs or plr is None:
        return "info", "PLR disponible solo con LUFS real (instala 'pyloudnorm').", 0.0
    
    # TRACK 1: Calcular (language-neutral)
    status, score = calculate_plr_score(plr, has_real_lufs, strict)
    
    # TRACK 2: Formatear mensaje (Mat√≠as Voice - del eBook)
    mode = "strict" if strict else "normal"
    
    messages = {
        "perfect": {
            "strict": "Excelente PLR: din√°mica √≥ptima para entrega comercial.",
            "normal": f"La din√°mica est√° muy bien preservada (PLR: {plr:.1f} dB). No has sobre-limitado en el master bus, lo que me da mucho espacio para trabajar el volumen final sin sacrificar la musicalidad.",
        },
        "pass": {
            "strict": "PLR bueno para comercial, pero ‚â•14 dB es ideal para m√°xima flexibilidad.",
            "normal": "Muy buen PLR para mastering.",
        },
        "warning": f"La mezcla ya puede estar bastante limitada (PLR: {plr:.1f} dB). Revisa limitadores/compresores en el master bus. Si te gusta su color, mant√©nlos pero aj√∫stalos para que no reduzcan ganancia (sube threshold/ceiling). As√≠ conservas el car√°cter mientras recuperas din√°mica.",
        "critical": f"PLR muy bajo ({plr:.1f} dB): sobre-comprimida/limitada. Quita limitadores o aj√∫stalos para que el audio solo PASE sin reducci√≥n de ganancia (solo para color). Alternativamente, usa menos compresi√≥n en buses de grupos.",
    }
    
    # Seleccionar mensaje apropiado
    if status in ["perfect", "pass"]:
        message = messages[status][mode]
    else:
        message = messages[status]
    
    return status, message, score

def _status_stereo_es(corr: float, strict: bool = False) -> Tuple[str, str, float]:
    """
    Evaluaci√≥n de correlaci√≥n est√©reo en espa√±ol usando scoring engine UNIFICADO.
    Ahora usa calculate_stereo_score() para consistencia language-neutral.
    """
    # TRACK 1: Calcular (language-neutral)
    status, score = calculate_stereo_score(corr, strict)
    
    # TRACK 2: Formatear mensaje (Mat√≠as Voice - del eBook)
    messages = {
        "perfect": "Excelente correlaci√≥n est√©reo (mono compatible). La mezcla se traducir√° bien en todos los sistemas de reproducci√≥n.",
        "pass": "Buena correlaci√≥n est√©reo. La mezcla mantiene una imagen est√©reo saludable con buena compatibilidad en mono.",
        "warning": "La correlaci√≥n est√©reo muestra algunos problemas de fase. Revisa efectos est√©reo, reverbs y paneo. Prueba en mono para asegurarte de que no se pierde nada importante.",
        "critical": f"Correlaci√≥n est√©reo baja ({corr:.2f}). Riesgo significativo de cancelaci√≥n de fase en reproducci√≥n mono. Esto puede hacer que instrumentos o voces pierdan volumen o desaparezcan completamente en sistemas mono (parlantes Bluetooth, tel√©fonos, clubes).",
        "catastrophic": f"SEVERO: Inversi√≥n de fase casi total detectada ({corr:.2f}). La mezcla se cancelar√° casi por completo en mono. Verifica: plugins con fase invertida, errores en procesamiento M/S, o canales accidentalmente invertidos.",
    }
    
    message = messages[status]
    
    return status, message, score

def _status_freq_es(fb: Dict[str, float], genre: Optional[str] = None, strict: bool = False) -> Tuple[str, str, float]:
    """
    Eval√∫a balance de frecuencias relativo a los medios usando deltas dB.
    Porcentajes son informativos √∫nicamente (dependen del arreglo).
    
    UMBRALES UNIFICADOS (language-neutral): Id√©nticos a EN para consistencia.
    """
    dL = fb["d_low_mid_db"]
    dH = fb["d_high_mid_db"]
    
    # Rangos amplios "mix-for-mastering" (UNIFICADOS)
    low_perfect = (-6.0, 6.0)
    low_pass = (-9.0, 9.0)
    high_perfect = (-15.0, 10.0)  # UNIFICADO: era muy permisivo
    high_pass = (-18.0, 12.0)      # UNIFICADO: era muy permisivo

    # Strict mode: tolerancia ligeramente m√°s estrecha (entrega comercial)
    if strict:
        low_perfect = (-5.0, 5.0)
        low_pass = (-8.0, 8.0)
        high_perfect = (-12.0, 8.0)   # UNIFICADO
        high_pass = (-15.0, 10.0)     # UNIFICADO

    def in_range(x, r):
        return r[0] <= x <= r[1]

    if in_range(dL, low_perfect) and in_range(dH, high_perfect):
        return "perfect", "Balance tonal saludable para mastering.", 1.0
    if in_range(dL, low_pass) and in_range(dH, high_pass):
        return "pass", "Balance tonal generalmente saludable para mastering.", 0.7

    # Fuera de rango pass: advertir, pero no sobre-penalizar (puede ser art√≠stico)
    msg_parts = []
    if dL > low_pass[1]:
        msg_parts.append("Graves pesados vs medios")
    elif dL < low_pass[0]:
        msg_parts.append("Graves ligeros vs medios")
    if dH > high_pass[1]:
        msg_parts.append("Agudos brillantes vs medios")
    elif dH < high_pass[0]:
        msg_parts.append("Agudos oscuros vs medios")

    msg = "Balance tonal con car√°cter; verifica traducci√≥n en m√∫ltiples sistemas. (" + ", ".join(msg_parts) + ")." if msg_parts else "Balance tonal con car√°cter; verifica traducci√≥n en m√∫ltiples sistemas."
    return "warning", msg, 0.4

def _status_crest_factor_es(crest: float) -> Tuple[str, str, float]:
    """Eval√∫a crest factor cuando LUFS no est√° disponible."""
    if crest >= 18.0:
        return "perfect", "Excelente din√°mica preservada (crest factor alto).", 1.0
    if crest >= 14.0:
        return "pass", "Buena din√°mica para mastering.", 0.7
    if crest >= 10.0:
        return "warning", "Din√°mica algo comprimida. Revisa compresi√≥n en el bus.", 0.4
    return "critical", "Din√°mica muy comprimida/limitada. Reduce procesamiento en master bus.", -0.5

def _status_dc_offset_es(dc_data: Dict[str, Any]) -> Tuple[str, str, float]:
    """Eval√∫a DC offset."""
    if not dc_data["detected"]:
        return "perfect", "Sin DC offset detectado.", 1.0
    
    max_offset = dc_data["max_offset"]
    if max_offset > 0.05:
        return "warning", f"DC offset significativo ({max_offset:.3f}). Aplica DC offset removal antes de exportar.", 0.3
    return "pass", f"DC offset menor detectado ({max_offset:.3f}). Considerar limpiar.", 0.6


# ----------------------------
# Status evaluators (bilingual)
# ----------------------------

def _pick_lang(lang: str) -> str:

    lang = (lang or 'en').lower().strip()

    return 'es' if lang.startswith('es') else 'en'



def status_headroom(peak_db: float, strict: bool = False, lang: str = 'en') -> Tuple[str, str, float]:

    lang = _pick_lang(lang)

    return _status_headroom_es(peak_db, strict) if lang == 'es' else _status_headroom_en(peak_db, strict)



def status_true_peak(tp_db: float, strict: bool = False, lang: str = 'en') -> Tuple[str, str, float, bool]:

    lang = _pick_lang(lang)

    return _status_true_peak_es(tp_db, strict) if lang == 'es' else _status_true_peak_en(tp_db, strict)



def status_lufs(lufs: Optional[float], method: str, is_reliable: bool, lang: str = 'en') -> Tuple[str, str, float]:

    lang = _pick_lang(lang)

    return _status_lufs_es(lufs, method, is_reliable) if lang == 'es' else _status_lufs_en(lufs, method, is_reliable)



def status_plr(plr: Optional[float], has_real_lufs: bool, strict: bool = False, lang: str = 'en') -> Tuple[str, str, float]:

    lang = _pick_lang(lang)

    return _status_plr_es(plr, has_real_lufs, strict) if lang == 'es' else _status_plr_en(plr, has_real_lufs, strict)



def status_stereo(corr: float, lang: str = 'en') -> Tuple[str, str, float]:

    lang = _pick_lang(lang)

    return _status_stereo_es(corr) if lang == 'es' else _status_stereo_en(corr)



def status_freq(fb: Dict[str, float], genre: Optional[str] = None, strict: bool = False, lang: str = 'en') -> Tuple[str, str, float]:

    lang = _pick_lang(lang)

    return _status_freq_es(fb, genre, strict) if lang == 'es' else _status_freq_en(fb, genre, strict)



def status_crest_factor(crest: float, lang: str = 'en') -> Tuple[str, str, float]:

    lang = _pick_lang(lang)

    return _status_crest_factor_es(crest) if lang == 'es' else _status_crest_factor_en(crest)



def status_dc_offset(dc_data: Dict[str, Any], lang: str = 'en') -> Tuple[str, str, float]:

    lang = _pick_lang(lang)

    return _status_dc_offset_es(dc_data) if lang == 'es' else _status_dc_offset_en(dc_data)



def score_report(metrics: List[Dict[str, Any]], hard_fail: bool, strict: bool = False, lang: str = 'en') -> Tuple[int, str]:
    """Calculate global score (0-100) and verdict with localization support."""
    lang = _pick_lang(lang)
    
    if hard_fail:
        if lang == 'es':
            return 0, "‚ùå Se requieren ajustes antes del mastering"
        return 0, "‚ùå Adjustments required before mastering"

    mult = {"perfect": 1.0, "pass": 0.9, "warning": 0.7, "critical": 0.0, "catastrophic": 0.0, "info": 1.0}
    total = 0.0
    wsum = 0.0
    
    for m in metrics:
        # Use internal_key for weight lookup (always English)
        internal_key = m.get("internal_key", m["name"])
        w = WEIGHTS.get(internal_key, 0.0)
        if w <= 0:
            continue
        
        # Crest Factor solo cuenta si no hay PLR real
        if internal_key == "Crest Factor":
            has_plr = any(
                metric.get("internal_key", metric["name"]) == "PLR" 
                and metric.get("value") != "N/A" 
                for metric in metrics
            )
            if has_plr:
                continue  # Skip crest factor si tenemos PLR
            else:
                w = 0.15  # Usar peso de PLR si no hay PLR
        
        wsum += w
        total += w * mult.get(m["status"], 0.0)

    if wsum <= 0:
        if lang == 'es':
            return 50, "‚ö†Ô∏è Resultados parciales"
        return 50, "‚ö†Ô∏è Partial results"

    raw_score = int(round(100.0 * (total / wsum)))
    
    # Apply intelligent minimum score - never 0
    minimum_score = calculate_minimum_score(metrics)
    score = max(minimum_score, raw_score)
    
    # Localized verdicts with territory context
    if lang == 'es':
        if score >= 95:
            verdict = "‚úÖ Perfecta para mastering"
        elif score >= 85:
            verdict = "‚úÖ Lista para mastering"
        elif score >= 75:
            verdict = "‚ö†Ô∏è Aceptable (revisar recomendaciones)"
        elif score >= 60:
            verdict = "‚ö†Ô∏è Ajustes menores recomendados"
        elif score >= 40:
            verdict = "‚ùå Ajustes significativos necesarios"
        elif score >= 20:
            verdict = "‚ùå Requiere correcci√≥n urgente"
        else:
            verdict = "üö® Problemas cr√≠ticos m√∫ltiples detectados"
    else:
        if score >= 95:
            verdict = "‚úÖ Perfect for mastering"
        elif score >= 85:
            verdict = "‚úÖ Ready for mastering"
        elif score >= 75:
            verdict = "‚ö†Ô∏è Acceptable (review recommendations)"
        elif score >= 60:
            verdict = "‚ö†Ô∏è Minor adjustments recommended"
        elif score >= 40:
            verdict = "‚ùå Significant adjustments needed"
        elif score >= 20:
            verdict = "‚ùå Urgent correction required"
        else:
            verdict = "üö® Multiple critical issues detected"
    
    return score, verdict


def analyze_file(path: Path, oversample: int = 4, genre: Optional[str] = None, strict: bool = False, lang: str = "en") -> Dict[str, Any]:
    """Analyze a full audio file."""
    try:
        info = sf.info(str(path))
    except Exception as e:
        raise RuntimeError(f"Error leyendo archivo: {e}. Archivo corrupto o formato no soportado.")
    
    sr = int(info.samplerate)
    channels = int(info.channels)
    duration = float(info.duration)
    
    # Validar duraci√≥n m√≠nima
    if duration < 0.5:
        raise RuntimeError(f"Archivo demasiado corto ({duration:.2f}s). M√≠nimo 0.5s.")
    
    try:
        y, sr_loaded = librosa.load(str(path), sr=sr, mono=False)
    except Exception as e:
        raise RuntimeError(f"Error cargando audio con librosa: {e}")
    
    if sr_loaded != sr:
        sr = int(sr_loaded)
    
    if y.ndim == 1:
        y = y[np.newaxis, :]

    # Auto-ajustar oversample si es necesario
    if oversample == 0:  # "auto" mode
        oversample = auto_oversample_factor(sr)

    metrics: List[Dict[str, Any]] = []

    # 1. Headroom with Clipping Temporal Analysis
    peak = peak_dbfs(y)
    headroom = -peak
    sample_peak = float(np.max(np.abs(y))) if y.size else 0.0
    clipping = sample_peak >= 0.999999
    
    # Temporal analysis if clipping detected
    clipping_temporal = None
    if clipping:
        clipping_temporal = analyze_clipping_temporal(y, sr, threshold=0.999999)

    st, msg, _ = status_headroom(peak, strict, lang)
    
    headroom_metric = {
        "name": METRIC_NAMES[_pick_lang(lang)]["Headroom"],
        "internal_key": "Headroom",
        "value": f"{headroom:.1f} dB",
        "peak_db": f"{peak:.1f} dBFS",
        "status": st,
        "message": msg
    }
    
    if clipping_temporal:
        headroom_metric["clipping_temporal"] = clipping_temporal
    
    metrics.append(headroom_metric)

    # 2. True Peak with Temporal Analysis
    tp = oversampled_true_peak_db(y, os_factor=oversample)
    st_tp, msg_tp, _, tp_hard = status_true_peak(tp, strict, lang)
    
    # Temporal analysis if problematic
    tp_temporal = None
    if tp > -1.0:  # Analyze if close to or above limit
        tp_temporal = analyze_true_peak_temporal(y, sr, oversample, threshold=0.0)
    
    tp_metric = {
        "name": METRIC_NAMES[_pick_lang(lang)]["True Peak"],
        "internal_key": "True Peak",
        "value": f"{tp:.1f} dBTP",
        "status": st_tp,
        "message": msg_tp
    }
    
    if tp_temporal:
        tp_metric["temporal_analysis"] = tp_temporal
    
    metrics.append(tp_metric)

    # 3. DC Offset
    dc_data = detect_dc_offset(y)
    st_dc, msg_dc, _ = status_dc_offset(dc_data, lang)
    
    lang_picked = _pick_lang(lang)
    dc_value = f"{dc_data['max_offset']:.4f}" if dc_data["detected"] else ("No detectado" if lang_picked == 'es' else "Not detected")
    
    metrics.append({
        "name": METRIC_NAMES[lang_picked]["DC Offset"],
        "internal_key": "DC Offset",  # For WEIGHTS lookup
        "value": dc_value,
        "status": st_dc,
        "message": msg_dc,
        "details": dc_data
    })

    # 4. LUFS
    lufs, lufs_method, lufs_reliable = integrated_lufs(y, sr, duration)
    lufs_label = "LUFS" if HAS_PYLOUDNORM else "RMS(dBFS) approx"
    st_l, msg_l, _ = status_lufs(lufs, lufs_method, lufs_reliable, lang)
    
    metrics.append({
        "name": METRIC_NAMES[_pick_lang(lang)]["LUFS (Integrated)"],
        "internal_key": "LUFS (Integrated)",  # For WEIGHTS lookup
        "value": f"{lufs:.1f} {lufs_label}" if lufs is not None else "N/A",
        "status": st_l,
        "message": f"{msg_l} (method: {lufs_method})",
        "method": lufs_method,
        "reliable": lufs_reliable
    })

    # 5. PLR
    plr = None
    has_real_lufs = HAS_PYLOUDNORM and lufs_method.startswith("pyloudnorm")
    if has_real_lufs and lufs is not None:
        plr = tp - lufs
    
    st_p, msg_p, _ = status_plr(plr, has_real_lufs, strict, lang)
    metrics.append({
        "name": METRIC_NAMES[_pick_lang(lang)]["PLR"],
        "internal_key": "PLR",  # For WEIGHTS lookup
        "value": f"{plr:.1f} dB" if plr is not None else "N/A",
        "status": st_p,
        "message": msg_p
    })

    # 6. Crest Factor (alternativa a PLR cuando no hay LUFS real)
    crest = calculate_crest_factor(y)
    st_cf, msg_cf, _ = status_crest_factor(crest, lang)
    
    lang_picked = _pick_lang(lang)
    if has_real_lufs:
        cf_message = "Informativo (usa PLR como m√©trica principal de din√°mica)." if lang_picked == 'es' else "Informational (use PLR as the primary dynamics metric)."
    else:
        cf_message = msg_cf
    
    metrics.append({
        "name": METRIC_NAMES[lang_picked]["Crest Factor"],
        "internal_key": "Crest Factor",  # For WEIGHTS lookup
        "value": f"{crest:.1f} dB",
        "status": st_cf,
        "message": cf_message
    })

    # 7. Stereo Field Analysis (Correlation + M/S + L/R Balance) with Temporal Analysis
    corr = stereo_correlation(y)
    ms_ratio, mid_rms, side_rms = calculate_ms_ratio(y)
    lr_balance_db = calculate_lr_balance(y)
    
    # Temporal analysis for each parameter if problematic
    corr_temporal = None
    ms_temporal = None
    lr_temporal = None
    
    if corr < 0.5:  # Analyze if correlation is problematic
        corr_temporal = analyze_correlation_temporal(y, sr, threshold=0.3)
    
    if ms_ratio < 0.05 or ms_ratio > 1.5:  # Analyze if M/S is problematic
        ms_temporal = analyze_ms_ratio_temporal(y, sr, low_threshold=0.05, high_threshold=1.5)
    
    if abs(lr_balance_db) > 3.0:  # Analyze if L/R balance is problematic
        lr_temporal = analyze_lr_balance_temporal(y, sr, threshold=3.0)
    
    # Comprehensive evaluation with M/S and L/R context
    st_s, msg_s = evaluate_stereo_field_comprehensive(corr, ms_ratio, lr_balance_db, lang, strict)
    
    # Enhanced stereo metric with M/S and L/R info
    stereo_metric = {
        "name": METRIC_NAMES[_pick_lang(lang)]["Stereo Width"],
        "internal_key": "Stereo Width",
        "value": f"{corr*100:.0f}% corr | M/S: {ms_ratio:.2f} | L/R: {lr_balance_db:+.1f} dB",
        "correlation": corr,
        "ms_ratio": round(ms_ratio, 2),
        "lr_balance_db": round(lr_balance_db, 1),
        "status": st_s,
        "message": msg_s
    }
    
    # Add temporal analysis if available
    if corr_temporal:
        stereo_metric["correlation_temporal"] = corr_temporal
    if ms_temporal:
        stereo_metric["ms_temporal"] = ms_temporal
    if lr_temporal:
        stereo_metric["lr_temporal"] = lr_temporal
    
    metrics.append(stereo_metric)

    # 8. Frequency Balance
    fb = band_balance_db(y, sr)
    st_f, msg_f, _ = status_freq(fb, genre, strict, lang)  # ‚Üê FIXED: Added strict and lang parameters
    
    # Localize frequency band labels for Spanish users
    lang_picked = _pick_lang(lang)
    if lang_picked == 'es':
        low_label, mid_label, high_label = "Graves", "Medios", "Agudos"
        delta_low_mid = "ŒîG-M"
        delta_high_mid = "ŒîA-M"
    else:
        low_label, mid_label, high_label = "Low", "Mid", "High"
        delta_low_mid = "ŒîL-M"
        delta_high_mid = "ŒîH-M"
    
    metrics.append({
        "name": METRIC_NAMES[lang_picked]["Frequency Balance"],
        "internal_key": "Frequency Balance",  # For WEIGHTS lookup
        "value": (
            f"{low_label}: {fb['low_percent']:.0f}% | "
            f"{mid_label}: {fb['mid_percent']:.0f}% | "
            f"{high_label}: {fb['high_percent']:.0f}%"
        ),
        "value_detailed": (
            f"{low_label}: {fb['low_db']:.1f} dB ({fb['low_percent']:.0f}%) | "
            f"{mid_label}: {fb['mid_db']:.1f} dB ({fb['mid_percent']:.0f}%) | "
            f"{high_label}: {fb['high_db']:.1f} dB ({fb['high_percent']:.0f}%) | "
            f"{delta_low_mid}: {fb['d_low_mid_db']:+.1f} dB | "
            f"{delta_high_mid}: {fb['d_high_mid_db']:+.1f} dB"
        ),
        **fb,
        "status": st_f,
        "message": msg_f
    })

    # Hard fail conditions - only for severe technical issues
    # True peak hard fail comes from calculate_true_peak_score
    # Clipping detection
    hard_fail = bool(clipping) or bool(tp_hard)
    score, verdict = score_report(metrics, hard_fail, strict, lang)  # ‚Üê FIXED: Added strict and lang

    return {
        "file": {
            "path": str(path),
            "duration_seconds": round(duration, 2),
            "sample_rate_hz": sr,
            "channels": channels,
            "genre": genre if genre else "not specified"
        },
        "metrics": metrics,
        "score": score,
        "verdict": verdict,
        "notes": {
            "lufs_is_real": has_real_lufs,
            "lufs_reliable": lufs_reliable,
            "oversample_factor": oversample,
            "auto_oversample": oversample == auto_oversample_factor(sr),
            "clipping_detected": clipping,
            "dc_offset_detected": dc_data["detected"],
            "recommendations": generate_recommendations(metrics, score, genre, lang)
        }
    }


def generate_recommendations(metrics: List[Dict[str, Any]], score: int, genre: Optional[str], lang: str = 'en') -> List[str]:
    """Generate specific recommendations based on analysis with language support and temporal context."""
    lang = _pick_lang(lang)
    recs = []
    
    for m in metrics:
        # Skip informational metrics (like Crest Factor when PLR is available)
        internal_key = m.get("internal_key", m.get("name", ""))
        if internal_key == "Crest Factor" and "Informativo" in m.get("message", ""):
            continue
        if internal_key == "Crest Factor" and "use PLR" in m.get("message", ""):
            continue
        
        if m["status"] in ["critical", "warning"]:
            base_message = f"‚Ä¢ {m['name']}: {m['message']}"
            
            # Add temporal context if available
            temporal_suffix = ""
            
            # Check for various temporal analyses
            if "temporal_analysis" in m:
                temporal_suffix = format_temporal_message(m["temporal_analysis"], m['name'], lang)
            elif "clipping_temporal" in m:
                temporal_suffix = format_temporal_message(m["clipping_temporal"], m['name'], lang)
            elif "correlation_temporal" in m:
                temporal_suffix = format_temporal_message(m["correlation_temporal"], "Correlation", lang)
            elif "ms_temporal" in m:
                temporal_suffix = format_temporal_message(m["ms_temporal"], "M/S Ratio", lang)
            elif "lr_temporal" in m:
                temporal_suffix = format_temporal_message(m["lr_temporal"], "L/R Balance", lang)
            
            recs.append(base_message + temporal_suffix)
    
    if score < 75:
        if lang == 'es':
            recs.append("‚Ä¢ Considera revisar tu mezcla antes de enviarla a mastering")
        else:
            recs.append("‚Ä¢ Consider reviewing your mix before sending to mastering")
    
    if not HAS_PYLOUDNORM:
        if lang == 'es':
            recs.append("‚Ä¢ Instala 'pyloudnorm' para mediciones LUFS precisas: pip install pyloudnorm")
        else:
            recs.append("‚Ä¢ Install 'pyloudnorm' for precise LUFS measurements: pip install pyloudnorm")
    
    if genre:
        if lang == 'es':
            recs.append(f"‚Ä¢ An√°lisis optimizado para g√©nero: {genre}")
        else:
            recs.append(f"‚Ä¢ Analysis optimized for genre: {genre}")
    
    if not recs:
        if lang == 'es':
            return ["‚Ä¢ Tu mezcla est√° bien preparada para mastering"]
        else:
            return ["‚Ä¢ Your mix is well prepared for mastering"]
    
    return recs




def generate_cta(score: int, strict: bool, lang: str, mode: str = "write") -> str:
    """
    Generate conversational CTA based on mix score and mode.
    
    CRITICAL:
    - Short mode: NO CTA (returns empty string)
    - Write mode score ‚â•85: NO CTA (mix is ready)
    - Write mode score <85: CTA with next steps
    """
    # SHORT MODE: Never show CTA
    if mode == "short":
        return ""
    
    # WRITE MODE: Only show CTA if score <85
    if lang == 'es':
        # Spanish CTAs
        if score >= 85:
            # Mix is ready - no CTA needed
            return ""
        
        elif score >= 60:
            # Mix needs adjustments
            return (
                "\n\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
                "üîß SIGUIENTES PASOS\n"
                "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\n"
                "Esta mezcla necesita algunos ajustes antes de estar lista para mastering.\n\n"
                "Tienes dos caminos claros:\n\n"
                "1Ô∏è‚É£ Puedes hacer los ajustes recomendados en tu sesi√≥n, re-exportar la mezcla "
                "y volver a analizarla aqu√≠ para confirmar que ya est√° lista.\n\n"
                "2Ô∏è‚É£ Si prefieres, puedes compartirme los archivos de tu sesi√≥n y con gusto hago "
                "los ajustes necesarios para dejarla lista, y luego la masterizamos.\n\n"
                "La idea es que llegue al mastering con el espacio correcto para trabajar fino "
                "y que la m√∫sica respire."
            )
        
        else:
            # Mix requires significant work
            return (
                "\n\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
                "üîß SIGUIENTES PASOS\n"
                "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\n"
                "Esta mezcla necesita atenci√≥n en varios aspectos t√©cnicos antes del mastering.\n\n"
                "Tienes dos caminos claros:\n\n"
                "1Ô∏è‚É£ Puedes hacer los ajustes recomendados en tu sesi√≥n, re-exportar la mezcla "
                "y volver a analizarla aqu√≠ para confirmar que ya est√° lista.\n\n"
                "2Ô∏è‚É£ Si prefieres, puedes compartirme los archivos de tu sesi√≥n y con gusto hago "
                "los ajustes necesarios para dejarla lista, y luego la masterizamos.\n\n"
                "La idea es que llegue al mastering con el espacio correcto para trabajar fino "
                "y que la m√∫sica respire."
            )
    
    else:
        # English CTAs
        if score >= 85:
            # Mix is ready - no CTA needed
            return ""
        
        elif score >= 60:
            # Mix needs adjustments
            return (
                "\n\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
                "üîß NEXT STEPS\n"
                "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\n"
                "This mix needs a few adjustments before it's truly mastering-ready.\n\n"
                "You have two clear options:\n\n"
                "1Ô∏è‚É£ Apply the recommended tweaks in your session, re-export the mix, and "
                "re-run the analysis to confirm it's ready.\n\n"
                "2Ô∏è‚É£ If you prefer, you can share your session files and I'll help make the "
                "necessary adjustments to get it ready, then we can move on to mastering.\n\n"
                "The goal is for the mix to arrive with proper space so the mastering can be "
                "done with finesse and musicality."
            )
        
        else:
            # Mix requires significant work
            return (
                "\n\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
                "üîß NEXT STEPS\n"
                "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\n"
                "This mix requires attention to several technical aspects before mastering.\n\n"
                "You have two clear options:\n\n"
                "1Ô∏è‚É£ Apply the recommended tweaks in your session, re-export the mix, and "
                "re-run the analysis to confirm it's ready.\n\n"
                "2Ô∏è‚É£ If you prefer, you can share your session files and I'll help make the "
                "necessary adjustments to get it ready, then we can move on to mastering.\n\n"
                "The goal is for the mix to arrive with proper space so the mastering can be "
                "done with finesse and musicality."
            )


def build_technical_details(metrics: List[Dict], lang: str = 'es') -> str:
    """
    Build comprehensive technical details section.
    Used ONLY in write mode for well-scored mixes (‚â•85).
    Includes explanation of EVERY metric with context.
    """
    lang = _pick_lang(lang)
    
    if lang == 'es':
        details = "\n\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
        details += "üìä DETALLES T√âCNICOS COMPLETOS\n"
        details += "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\n"
        
        # HEADROOM
        headroom_metric = next((m for m in metrics if "Headroom" in m.get("internal_key", "")), None)
        if headroom_metric:
            peak_val = headroom_metric.get("peak_db", "")
            details += f"üéöÔ∏è HEADROOM: {peak_val}\n"
            details += "   ‚Üí Los picos dejan suficiente espacio para procesamiento\n"
            details += "     sin riesgo de clipping durante el mastering.\n"
            
            # Add temporal info if exists
            if "temporal_analysis" in headroom_metric:
                temporal = format_temporal_message(
                    headroom_metric["temporal_analysis"], 
                    "Headroom", 
                    lang
                )
                if temporal:
                    details += "  " + temporal.strip() + "\n"
            else:
                details += "   ‚Üí Headroom consistente en toda la canci√≥n.\n"
            details += "\n"
        
        # TRUE PEAK
        tp_metric = next((m for m in metrics if "True Peak" in m.get("internal_key", "")), None)
        if tp_metric:
            tp_val = tp_metric.get("value", "")
            details += f"üîä TRUE PEAK: {tp_val}\n"
            details += "   ‚Üí Seguro para conversi√≥n a formatos con p√©rdida (MP3, AAC, Spotify).\n"
            details += "     No habr√° distorsi√≥n intersample en streaming.\n"
            
            # Add temporal info
            if "temporal_analysis" in tp_metric:
                temporal = format_temporal_message(
                    tp_metric["temporal_analysis"],
                    "True Peak",
                    lang
                )
                if temporal:
                    details += "  " + temporal.strip() + "\n"
            else:
                details += "   ‚Üí M√°rgenes de seguridad cumplidos en todo el track.\n"
            details += "\n"
        
        # PLR (Dynamic Range)
        plr_metric = next((m for m in metrics if "PLR" in m.get("internal_key", "")), None)
        if plr_metric and plr_metric.get("value") != "N/A":
            plr_val = plr_metric.get("value", "")
            details += f"üìà RANGO DIN√ÅMICO (PLR): {plr_val}\n"
            
            # Contextual explanation based on value
            if isinstance(plr_val, str):
                try:
                    plr_num = float(plr_val.split()[0])
                    if plr_num >= 12:
                        details += "   ‚Üí Excelente preservaci√≥n de din√°mica. La mezcla respira bien.\n"
                        details += "   ‚Üí Ideal para mastering expresivo con punch natural.\n"
                    elif plr_num >= 8:
                        details += "   ‚Üí Buen rango din√°mico, apropiado para mastering.\n"
                    else:
                        details += "   ‚Üí Algo comprimida, pero a√∫n trabajable en mastering.\n"
                except:
                    details += "   ‚Üí Rango din√°mico medido.\n"
            details += "\n"
        
        # STEREO FIELD
        stereo_metric = next((m for m in metrics if "Stereo" in m.get("internal_key", "")), None)
        if stereo_metric:
            corr_val = stereo_metric.get("value", "")
            ms_ratio = stereo_metric.get("ms_ratio", 0)
            lr_balance = stereo_metric.get("lr_balance_db", 0)
            
            details += "üéß CAMPO EST√âREO:\n"
            details += f"   ‚Ä¢ Correlaci√≥n: {corr_val}\n"
            if ms_ratio:
                details += f"   ‚Ä¢ M/S Ratio: {ms_ratio:.2f}\n"
            if lr_balance is not None:
                details += f"   ‚Ä¢ L/R Balance: {abs(lr_balance):.1f} dB\n"
            details += "\n"
            
            # Check for temporal analysis (from chunked mode)
            if "temporal_analysis" in stereo_metric:
                temporal = stereo_metric["temporal_analysis"]
                
                details += "‚ö†Ô∏è AN√ÅLISIS TEMPORAL:\n\n"
                
                # Correlation temporal
                if 'correlation' in temporal:
                    corr_data = temporal['correlation']
                    num_regions = corr_data.get('num_regions', 0)
                    regions = corr_data.get('regions', [])
                    
                    if num_regions > 0:
                        details += f"üîä Correlaci√≥n ({num_regions} regi√≥n{'es' if num_regions > 1 else ''} problem√°tica{'s' if num_regions > 1 else ''}):\n"
                        for region in regions[:5]:
                            start_min = int(region['start'] // 60)
                            start_sec = int(region['start'] % 60)
                            end_min = int(region['end'] // 60)
                            end_sec = int(region['end'] % 60)
                            dur = int(region['duration'])
                            corr = region['avg_correlation']
                            issue = region['issue']
                            
                            details += f"   ‚Ä¢ {start_min}:{start_sec:02d} ‚Üí {end_min}:{end_sec:02d} ({dur}s): "
                            if issue == 'low':
                                details += f"Correlaci√≥n baja ({corr*100:.0f}%)\n"
                                details += "      ‚Üí Posible phase issues\n"
                            else:
                                details += f"Correlaci√≥n muy alta ({corr*100:.0f}%)\n"
                                details += "      ‚Üí Casi mono\n"
                        details += "\n"
                
                # M/S Ratio temporal
                if 'ms_ratio' in temporal:
                    ms_data = temporal['ms_ratio']
                    num_regions = ms_data.get('num_regions', 0)
                    regions = ms_data.get('regions', [])
                    
                    if num_regions > 0:
                        details += f"üìê M/S Ratio ({num_regions} regi√≥n{'es' if num_regions > 1 else ''} problem√°tica{'s' if num_regions > 1 else ''}):\n"
                        for region in regions[:5]:
                            start_min = int(region['start'] // 60)
                            start_sec = int(region['start'] % 60)
                            end_min = int(region['end'] // 60)
                            end_sec = int(region['end'] % 60)
                            dur = int(region['duration'])
                            ms = region['avg_ms_ratio']
                            issue = region['issue']
                            
                            details += f"   ‚Ä¢ {start_min}:{start_sec:02d} ‚Üí {end_min}:{end_sec:02d} ({dur}s): "
                            if issue == 'mono':
                                details += f"Ratio bajo ({ms:.2f})\n"
                                details += "      ‚Üí Mezcla muy mono\n"
                            else:
                                details += f"Ratio alto ({ms:.2f})\n"
                                details += "      ‚Üí Exceso de informaci√≥n Side\n"
                        details += "\n"
                
                # L/R Balance temporal
                if 'lr_balance' in temporal:
                    lr_data = temporal['lr_balance']
                    num_regions = lr_data.get('num_regions', 0)
                    regions = lr_data.get('regions', [])
                    
                    if num_regions > 0:
                        details += f"‚öñÔ∏è Balance L/R ({num_regions} regi√≥n{'es' if num_regions > 1 else ''} problem√°tica{'s' if num_regions > 1 else ''}):\n"
                        for region in regions[:5]:
                            start_min = int(region['start'] // 60)
                            start_sec = int(region['start'] % 60)
                            end_min = int(region['end'] // 60)
                            end_sec = int(region['end'] % 60)
                            dur = int(region['duration'])
                            balance = region['avg_balance_db']
                            side = region['side']
                            
                            details += f"   ‚Ä¢ {start_min}:{start_sec:02d} ‚Üí {end_min}:{end_sec:02d} ({dur}s): "
                            if side == 'left':
                                details += f"Desbalance L: +{abs(balance):.1f} dB\n"
                            else:
                                details += f"Desbalance R: {balance:.1f} dB\n"
                        details += "\n"
                
                details += "üí° Revisa los timestamps indicados en tu DAW.\n\n"
            
            else:
                # No temporal analysis available
                details += "   ‚Üí Imagen est√©reo con buena compatibilidad mono.\n"
                details += "     Se traducir√° bien en diferentes sistemas.\n\n"
        
        # FREQUENCY BALANCE
        freq_metric = next((m for m in metrics if "Frequency" in m.get("internal_key", "")), None)
        if freq_metric:
            bass = freq_metric.get("bass_pct", 0)
            mid = freq_metric.get("mid_pct", 0)
            high = freq_metric.get("high_pct", 0)
            
            details += "üéº BALANCE DE FRECUENCIAS:\n"
            if bass:
                details += f"   ‚Ä¢ Graves (20-250 Hz): {bass:.0f}%\n"
            if mid:
                details += f"   ‚Ä¢ Medios (250 Hz-4 kHz): {mid:.0f}%\n"
            if high:
                details += f"   ‚Ä¢ Agudos (4 kHz-20 kHz): {high:.0f}%\n"
            details += "\n"
            details += "   ‚Üí Distribuci√≥n tonal balanceada.\n"
        
        return details
    
    else:  # English
        details = "\n\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
        details += "üìä COMPLETE TECHNICAL DETAILS\n"
        details += "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\n"
        
        # HEADROOM
        headroom_metric = next((m for m in metrics if "Headroom" in m.get("internal_key", "")), None)
        if headroom_metric:
            peak_val = headroom_metric.get("peak_db", "")
            details += f"üéöÔ∏è HEADROOM: {peak_val}\n"
            details += "   ‚Üí Peaks leave sufficient space for processing\n"
            details += "     without risk of clipping during mastering.\n"
            
            if "temporal_analysis" in headroom_metric:
                temporal = format_temporal_message(
                    headroom_metric["temporal_analysis"], 
                    "Headroom", 
                    lang
                )
                if temporal:
                    details += "  " + temporal.strip() + "\n"
            else:
                details += "   ‚Üí Consistent headroom throughout the song.\n"
            details += "\n"
        
        # TRUE PEAK
        tp_metric = next((m for m in metrics if "True Peak" in m.get("internal_key", "")), None)
        if tp_metric:
            tp_val = tp_metric.get("value", "")
            details += f"üîä TRUE PEAK: {tp_val}\n"
            details += "   ‚Üí Safe for lossy format conversion (MP3, AAC, Spotify).\n"
            details += "     No intersample distortion in streaming.\n"
            
            if "temporal_analysis" in tp_metric:
                temporal = format_temporal_message(
                    tp_metric["temporal_analysis"],
                    "True Peak",
                    lang
                )
                if temporal:
                    details += "  " + temporal.strip() + "\n"
            else:
                details += "   ‚Üí Safety margins met throughout the track.\n"
            details += "\n"
        
        # PLR
        plr_metric = next((m for m in metrics if "PLR" in m.get("internal_key", "")), None)
        if plr_metric and plr_metric.get("value") != "N/A":
            plr_val = plr_metric.get("value", "")
            details += f"üìà DYNAMIC RANGE (PLR): {plr_val}\n"
            
            if isinstance(plr_val, str):
                try:
                    plr_num = float(plr_val.split()[0])
                    if plr_num >= 12:
                        details += "   ‚Üí Excellent dynamic preservation. Mix breathes well.\n"
                        details += "   ‚Üí Ideal for expressive mastering with natural punch.\n"
                    elif plr_num >= 8:
                        details += "   ‚Üí Good dynamic range, appropriate for mastering.\n"
                    else:
                        details += "   ‚Üí Somewhat compressed, but still workable in mastering.\n"
                except:
                    details += "   ‚Üí Dynamic range measured.\n"
            details += "\n"
        
        # STEREO FIELD
        stereo_metric = next((m for m in metrics if "Stereo" in m.get("internal_key", "")), None)
        if stereo_metric:
            corr_val = stereo_metric.get("value", "")
            ms_ratio = stereo_metric.get("ms_ratio", 0)
            lr_balance = stereo_metric.get("lr_balance_db", 0)
            
            details += "üéß STEREO FIELD:\n"
            details += f"   ‚Ä¢ Correlation: {corr_val}\n"
            if ms_ratio:
                details += f"   ‚Ä¢ M/S Ratio: {ms_ratio:.2f}\n"
            if lr_balance is not None:
                details += f"   ‚Ä¢ L/R Balance: {abs(lr_balance):.1f} dB\n"
            details += "\n"
            details += "   ‚Üí Stereo image with good mono compatibility.\n"
            details += "     Will translate well across systems.\n\n"
        
        # FREQUENCY BALANCE
        freq_metric = next((m for m in metrics if "Frequency" in m.get("internal_key", "")), None)
        if freq_metric:
            bass = freq_metric.get("bass_pct", 0)
            mid = freq_metric.get("mid_pct", 0)
            high = freq_metric.get("high_pct", 0)
            
            details += "üéº FREQUENCY BALANCE:\n"
            if bass:
                details += f"   ‚Ä¢ Lows (20-250 Hz): {bass:.0f}%\n"
            if mid:
                details += f"   ‚Ä¢ Mids (250 Hz-4 kHz): {mid:.0f}%\n"
            if high:
                details += f"   ‚Ä¢ Highs (4 kHz-20 kHz): {high:.0f}%\n"
            details += "\n"
            details += "   ‚Üí Balanced tonal distribution.\n"
        
        return details


def analyze_file_chunked(
    path: Path,
    oversample: int = 4,
    genre: Optional[str] = None,
    strict: bool = False,
    lang: str = "en",
    chunk_duration: float = 30.0,
    progress_callback = None
) -> Dict[str, Any]:
    """
    Memory-optimized analysis for large files using chunked processing.
    Processes audio in chunks to avoid loading entire file into memory.
    
    Args:
        path: Audio file path
        oversample: Oversampling factor for true peak (1, 2, 4, or 'auto')
        genre: Genre hint for frequency balance evaluation
        strict: Use stricter commercial standards
        lang: Language for reports ('en' or 'es')
        chunk_duration: Duration of each chunk in seconds (default: 30s)
        progress_callback: Optional callback function(progress_value) for progress updates
    
    Returns:
        Same structure as analyze_file() but with chunked=True flag
    """
    
    print("============================================================")
    print("üîÑ CHUNKED ANALYSIS - Memory Optimized")
    print("============================================================")
    
    # 1. Get file metadata without loading audio
    import soundfile as sf
    
    file_info = sf.info(str(path))
    sr = file_info.samplerate
    channels = file_info.channels
    duration = file_info.duration
    file_size = path.stat().st_size
    
    print(f"üìÅ File: {path.name}")
    print(f"üì¶ Chunk size: {chunk_duration} seconds")
    print(f"‚è±Ô∏è  Duration: {duration:.1f} seconds ({duration/60:.1f} minutes)")
    print(f"üìä Sample rate: {sr} Hz")
    print(f"üîä Channels: {channels}")
    print(f"üíæ File size: {file_size / (1024*1024):.1f} MB")
    
    # Calculate number of chunks
    num_chunks = int(np.ceil(duration / chunk_duration))
    print(f"üì¶ Processing in {num_chunks} chunks")
    
    # 2. Initialize accumulators
    results = {
        'peaks': [],
        'tps': [],
        'lufs_values': [],
        'correlations': [],
        'lr_balances': [],
        'ms_ratios': [],
        'chunk_durations': [],
        'tp_problem_chunks': [],           # Track chunks with TP > -1.0 dBTP
        'clipping_chunks': [],              # Track chunks with sample clipping
        'correlation_problem_chunks': [],   # Track chunks with correlation issues
        'ms_ratio_problem_chunks': [],      # Track chunks with M/S ratio issues
        'lr_balance_problem_chunks': []     # Track chunks with L/R balance issues
    }
    
    # 3. Process each chunk
    for i in range(num_chunks):
        start_time = i * chunk_duration
        actual_chunk_duration = min(chunk_duration, duration - start_time)
        
        print(f"üì¶ Chunk {i+1}/{num_chunks} (offset: {start_time:.1f}s, duration: {actual_chunk_duration:.1f}s)")
        
        # Load only this chunk (STEREO)
        y, _ = librosa.load(
            str(path),
            sr=sr,
            offset=start_time,
            duration=actual_chunk_duration,
            mono=False  # ‚Üê CRITICAL: Keep stereo
        )
        
        # Ensure correct format (channels, samples)
        if y.ndim == 1:
            # Mono file - convert to pseudo-stereo
            y = np.stack([y, y])
        elif y.shape[0] > y.shape[1]:
            # Transpose if needed
            y = y.T
        
        print(f"   Loaded: {y.shape[0]} channels, {y.shape[1]} samples (~{y.nbytes / (1024*1024):.1f} MB)")
        
        # Calculate metrics for this chunk
        try:
            # Peak
            chunk_peak = np.max(np.abs(y))
            chunk_peak_db = 20 * np.log10(chunk_peak) if chunk_peak > 0 else -np.inf
            
            # True Peak (oversampled)
            chunk_tp_db = oversampled_true_peak_db(y, oversample)
            
            # LUFS (integrated)
            if HAS_PYLOUDNORM:
                meter = pyln.Meter(sr)
                chunk_lufs = meter.integrated_loudness(y.T)
            else:
                chunk_lufs = -23.0  # Safe default
            
            # Spatial metrics
            chunk_corr = stereo_correlation(y)
            chunk_lr = calculate_lr_balance(y)
            chunk_ms, _, _ = calculate_ms_ratio(y)
            
            # Store results
            results['peaks'].append(chunk_peak_db)
            results['tps'].append(chunk_tp_db)
            results['lufs_values'].append(chunk_lufs)
            results['correlations'].append(chunk_corr)
            results['lr_balances'].append(chunk_lr)
            results['ms_ratios'].append(chunk_ms)
            results['chunk_durations'].append(actual_chunk_duration)
            
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # SUB-CHUNK TEMPORAL ANALYSIS (5-second windows with 50% overlap)
            # Provides terminal-level precision (¬±2-3s) for problem detection
            # Uses same parameters as terminal: 5s windows, 50% overlap, 0.0 dBTP threshold
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            
            window_duration = 5.0  # seconds
            hop_duration = 2.5     # 50% overlap (like terminal)
            window_samples = int(window_duration * sr)
            hop_samples = int(hop_duration * sr)
            
            # Calculate number of windows with overlap
            num_samples = y.shape[1]
            num_windows = int(np.ceil((num_samples - window_samples) / hop_samples)) + 1
            
            for w in range(num_windows):
                window_offset = w * hop_samples
                window_end = min(window_offset + window_samples, num_samples)
                
                # Skip if window is too short
                if window_end - window_offset < sr:  # Less than 1 second
                    continue
                
                window = y[:, window_offset:window_end]
                window_time = start_time + (window_offset / sr)
                window_dur = (window_end - window_offset) / sr
                
                # 1. True Peak temporal (per window)
                # Terminal uses threshold of 0.0 dBTP (not -1.0)
                window_tp = oversampled_true_peak_db(window, oversample)
                if window_tp > 0.0:  # Changed from -1.0 to 0.0 (terminal threshold)
                    results['tp_problem_chunks'].append({
                        'chunk': i + 1,
                        'window': w + 1,
                        'start_time': window_time,
                        'end_time': window_time + window_dur,
                        'tp_db': window_tp
                    })
                
                # 2. Sample clipping temporal (per window)
                window_peak = np.max(np.abs(window))
                if window_peak >= 0.999999:
                    results['clipping_chunks'].append({
                        'chunk': i + 1,
                        'window': w + 1,
                        'start_time': window_time,
                        'end_time': window_time + window_dur,
                        'peak': window_peak
                    })
                
                # 3. Stereo correlation temporal (per window)
                window_corr = stereo_correlation(window)
                if window_corr < 0.3:
                    results['correlation_problem_chunks'].append({
                        'chunk': i + 1,
                        'window': w + 1,
                        'start_time': window_time,
                        'end_time': window_time + window_dur,
                        'correlation': window_corr,
                        'issue': 'low',
                        'severity': 'critical' if window_corr < 0.1 else 'warning'
                    })
                elif window_corr > 0.95:
                    results['correlation_problem_chunks'].append({
                        'chunk': i + 1,
                        'window': w + 1,
                        'start_time': window_time,
                        'end_time': window_time + window_dur,
                        'correlation': window_corr,
                        'issue': 'high',
                        'severity': 'warning'
                    })
                
                # 4. M/S Ratio temporal (per window)
                window_ms, _, _ = calculate_ms_ratio(window)
                if window_ms < 0.1:
                    results['ms_ratio_problem_chunks'].append({
                        'chunk': i + 1,
                        'window': w + 1,
                        'start_time': window_time,
                        'end_time': window_time + window_dur,
                        'ms_ratio': window_ms,
                        'issue': 'mono',
                        'severity': 'warning'
                    })
                elif window_ms > 1.2:
                    results['ms_ratio_problem_chunks'].append({
                        'chunk': i + 1,
                        'window': w + 1,
                        'start_time': window_time,
                        'end_time': window_time + window_dur,
                        'ms_ratio': window_ms,
                        'issue': 'too_wide',
                        'severity': 'warning'
                    })
                
                # 5. L/R Balance temporal (per window)
                window_lr = calculate_lr_balance(window)
                if abs(window_lr) > 2.0:
                    results['lr_balance_problem_chunks'].append({
                        'chunk': i + 1,
                        'window': w + 1,
                        'start_time': window_time,
                        'end_time': window_time + window_dur,
                        'lr_balance_db': window_lr,
                        'side': 'left' if window_lr > 0 else 'right',
                        'severity': 'critical' if abs(window_lr) > 3.0 else 'warning'
                    })
            
            print(f"   ‚úÖ Peak: {chunk_peak_db:.1f} dBFS, TP: {chunk_tp_db:.1f} dBTP, LUFS: {chunk_lufs:.1f}")
            
            # Update progress callback if provided
            # Progress: 10% (file loaded) + 60% (chunks processing) = 10-70%
            if progress_callback:
                chunk_progress = 10 + int((i + 1) / num_chunks * 60)
                progress_callback(chunk_progress)
            
        except Exception as e:
            print(f"   ‚ùå Error in chunk {i+1}: {e}")
            # Use safe defaults
            results['peaks'].append(-60.0)
            results['tps'].append(-60.0)
            results['lufs_values'].append(-40.0)
            results['correlations'].append(0.5)
            results['lr_balances'].append(0.0)
            results['ms_ratios'].append(0.3)
            results['chunk_durations'].append(actual_chunk_duration)
    
    print("============================================================")
    print("Aggregating results...")
    print("============================================================")
    
    # 4. Aggregate results using weighted average
    total_duration = sum(results['chunk_durations'])
    
    # Weighted averages
    final_peak = max(results['peaks']) if results['peaks'] else -60.0
    final_tp = max(results['tps']) if results['tps'] else -60.0
    
    # LUFS: weighted average
    weighted_lufs = sum(
        lufs * dur for lufs, dur in zip(results['lufs_values'], results['chunk_durations'])
    ) / total_duration if total_duration > 0 else -23.0
    
    # PLR: difference between peak and LUFS
    final_plr = final_peak - weighted_lufs
    
    # Stereo metrics: weighted averages
    final_correlation = sum(
        corr * dur for corr, dur in zip(results['correlations'], results['chunk_durations'])
    ) / total_duration if total_duration > 0 else 0.5
    
    final_lr_balance = sum(
        lr * dur for lr, dur in zip(results['lr_balances'], results['chunk_durations'])
    ) / total_duration if total_duration > 0 else 0.0
    
    final_ms_ratio = sum(
        ms * dur for ms, dur in zip(results['ms_ratios'], results['chunk_durations'])
    ) / total_duration if total_duration > 0 else 0.3
    
    print(f"‚úÖ Peak: {final_peak:.2f} dBFS")
    print(f"‚úÖ True Peak: {final_tp:.2f} dBTP")
    print(f"‚úÖ LUFS: {weighted_lufs:.2f}")
    print(f"‚úÖ PLR: {final_plr:.2f} dB")
    print(f"‚úÖ Correlation: {final_correlation:.3f}")
    print(f"‚úÖ L/R Balance: {final_lr_balance:+.2f} dB")
    print(f"‚úÖ M/S Ratio: {final_ms_ratio:.2f}")
    
    # 5. Detect territory and mastered status
    territory = detect_territory(weighted_lufs, final_peak, final_tp, final_plr)
    is_mastered = detect_mastered_file(weighted_lufs, final_peak, final_tp, final_plr, 0.0)
    
    print(f"üìç Territory: {territory}")
    print(f"üéõÔ∏è  {'Mastered' if is_mastered else 'Mix (not mastered)'}")
    print("============================================================")
    
    # Helper function to merge consecutive chunks into regions
    def merge_chunks_into_regions(problem_chunks, gap_threshold=2.5):
        """
        Merge consecutive problem chunks into continuous regions.
        
        Gap threshold of 2.5s matches terminal behavior:
        - Small gaps (< 2.5s) are absorbed into continuous regions
        - Larger gaps create separate regions
        - Results in practical, user-friendly region reporting
        
        Example:
          Windows: 30-35s, 35-40s, [gap 2s], 42-47s, 47-52s
          Result: One region 30-52s (gap < 2.5s absorbed)
        """
        print(f"üîß merge_chunks_into_regions called with gap_threshold={gap_threshold}s")
        if not problem_chunks:
            return []
        
        regions = []
        current_region = {
            'start': problem_chunks[0]['start_time'],
            'end': problem_chunks[0]['end_time'],
            'chunks': [problem_chunks[0]]
        }
        
        for chunk in problem_chunks[1:]:
            # If this chunk is consecutive (within gap_threshold seconds), extend region
            if chunk['start_time'] - current_region['end'] < gap_threshold:
                current_region['end'] = chunk['end_time']
                current_region['chunks'].append(chunk)
            else:
                # Save current region and start new one
                regions.append(current_region)
                current_region = {
                    'start': chunk['start_time'],
                    'end': chunk['end_time'],
                    'chunks': [chunk]
                }
        
        # Don't forget last region
        regions.append(current_region)
        return regions
    
    # Build metrics array using the ACTUAL evaluation functions from analyzer
    # This ensures IDENTICAL scoring between normal and chunked analysis
    
    metrics = []
    lang_picked = "es" if lang == "es" else "en"
    
    # Import evaluation functions
    from analyzer import (
        status_headroom, status_true_peak, status_dc_offset,
        status_lufs, status_plr, status_crest_factor,
        evaluate_stereo_field_comprehensive, status_freq
    )
    
    # 1. Headroom
    # In dBFS, headroom is the peak level itself (negative value)
    # Headroom = distance to 0 dBFS ceiling = peak value
    headroom = final_peak  # Both are negative in dBFS (e.g., -6.28 dBFS)
    st_h, msg_h, _ = status_headroom(final_peak, strict, lang)
    
    # Build clipping temporal analysis if there are clipping chunks
    clipping_temporal = None
    if results['clipping_chunks']:
        # Merge consecutive chunks into regions
        regions = merge_chunks_into_regions(results['clipping_chunks'])
        
        clipping_temporal = {
            'num_regions': len(regions),
            'regions': [{'start': r['start'], 'end': r['end']} for r in regions[:10]]
        }
    
    headroom_metric = {
        "name": "Headroom",
        "internal_key": "Headroom",
        "value": f"{headroom:.1f} dBFS",
        "status": st_h,
        "message": msg_h,
        "peak_db": f"{final_peak:.1f} dBFS"
    }
    
    if clipping_temporal:
        headroom_metric["clipping_temporal"] = clipping_temporal
    
    metrics.append(headroom_metric)
    
    # 2. True Peak
    st_tp, msg_tp, _, tp_hard = status_true_peak(final_tp, strict, lang)
    
    # Build temporal analysis if there are problem chunks
    tp_temporal = None
    if results['tp_problem_chunks']:
        # FIRST: Merge consecutive chunks into regions
        regions = merge_chunks_into_regions(results['tp_problem_chunks'])
        
        # THEN: Calculate percentage based on MERGED REGIONS (not individual windows)
        # This avoids double-counting overlapping windows
        problem_duration = sum(
            region['end'] - region['start']
            for region in regions
        )
        percentage = (problem_duration / duration) * 100 if duration > 0 else 0
        
        tp_temporal = {
            'total_time_above_threshold': problem_duration,
            'percentage_above_threshold': percentage,
            'num_regions': len(regions),
            'regions': [{'start': r['start'], 'end': r['end']} for r in regions[:10]]
        }
    
    tp_metric = {
        "name": "True Peak",
        "internal_key": "True Peak",
        "value": f"{final_tp:.1f} dBTP",
        "status": st_tp,
        "message": msg_tp
    }
    
    if tp_temporal:
        tp_metric["temporal_analysis"] = tp_temporal
    
    metrics.append(tp_metric)
    
    # 3. DC Offset (assume not detected in chunked analysis)
    dc_data = {"detected": False, "max_offset": 0.0}
    st_dc, msg_dc, _ = status_dc_offset(dc_data, lang)
    
    metrics.append({
        "name": "DC Offset",
        "internal_key": "DC Offset",
        "value": "No detectado" if lang == "es" else "Not detected",
        "status": st_dc,
        "message": msg_dc,
        "details": dc_data
    })
    
    # 4. LUFS
    lufs_reliable = duration >= MIN_DURATION_FOR_LUFS
    st_l, msg_l, _ = status_lufs(weighted_lufs, "chunked", lufs_reliable, lang)
    
    metrics.append({
        "name": "LUFS (Integrated)",
        "internal_key": "LUFS (Integrated)",
        "value": f"{weighted_lufs:.1f} LUFS",
        "status": st_l,
        "message": f"{msg_l} (method: chunked)",
        "method": "chunked",
        "reliable": lufs_reliable
    })
    
    # 5. PLR
    has_real_lufs = True  # chunked uses pyloudnorm
    st_p, msg_p, _ = status_plr(final_plr, has_real_lufs, strict, lang)
    
    metrics.append({
        "name": "PLR",
        "internal_key": "PLR",
        "value": f"{final_plr:.1f} dB",
        "status": st_p,
        "message": msg_p
    })
    
    # 6. Crest Factor (informational when we have real LUFS)
    crest = final_plr  # Similar to PLR for chunked analysis
    st_cf, msg_cf, _ = status_crest_factor(crest, lang)
    
    metrics.append({
        "name": "Crest Factor",
        "internal_key": "Crest Factor",
        "value": f"{crest:.1f} dB",
        "status": st_cf,
        "message": "Informativo (usa PLR como m√©trica principal de din√°mica)." if lang == "es" else "Informational (use PLR as the primary dynamics metric)."
    })
    
    # 7. Stereo Field (comprehensive evaluation)
    st_s, msg_s = evaluate_stereo_field_comprehensive(
        final_correlation, 
        final_ms_ratio, 
        final_lr_balance, 
        lang, 
        strict
    )
    
    # Build comprehensive stereo temporal analysis
    stereo_temporal = None
    has_stereo_problems = (
        results['correlation_problem_chunks'] or 
        results['ms_ratio_problem_chunks'] or 
        results['lr_balance_problem_chunks']
    )
    
    if has_stereo_problems:
        stereo_temporal = {}
        
        # 1. Correlation temporal analysis
        if results['correlation_problem_chunks']:
            corr_regions = merge_chunks_into_regions(results['correlation_problem_chunks'])
            stereo_temporal['correlation'] = {
                'num_regions': len(corr_regions),
                'regions': [
                    {
                        'start': r['start'],
                        'end': r['end'],
                        'duration': r['end'] - r['start'],
                        'avg_correlation': sum(c['correlation'] for c in r['chunks']) / len(r['chunks']),
                        'issue': r['chunks'][0]['issue'],  # 'low' or 'high'
                        'severity': max(c['severity'] for c in r['chunks'])  # worst severity in region
                    }
                    for r in corr_regions[:10]  # Limit to 10 regions
                ]
            }
        
        # 2. M/S Ratio temporal analysis
        if results['ms_ratio_problem_chunks']:
            ms_regions = merge_chunks_into_regions(results['ms_ratio_problem_chunks'])
            stereo_temporal['ms_ratio'] = {
                'num_regions': len(ms_regions),
                'regions': [
                    {
                        'start': r['start'],
                        'end': r['end'],
                        'duration': r['end'] - r['start'],
                        'avg_ms_ratio': sum(c['ms_ratio'] for c in r['chunks']) / len(r['chunks']),
                        'issue': r['chunks'][0]['issue'],  # 'mono' or 'too_wide'
                        'severity': max(c['severity'] for c in r['chunks'])
                    }
                    for r in ms_regions[:10]
                ]
            }
        
        # 3. L/R Balance temporal analysis
        if results['lr_balance_problem_chunks']:
            lr_regions = merge_chunks_into_regions(results['lr_balance_problem_chunks'])
            stereo_temporal['lr_balance'] = {
                'num_regions': len(lr_regions),
                'regions': [
                    {
                        'start': r['start'],
                        'end': r['end'],
                        'duration': r['end'] - r['start'],
                        'avg_balance_db': sum(c['lr_balance_db'] for c in r['chunks']) / len(r['chunks']),
                        'side': r['chunks'][0]['side'],  # 'left' or 'right'
                        'severity': max(c['severity'] for c in r['chunks'])
                    }
                    for r in lr_regions[:10]
                ]
            }
    
    stereo_metric = {
        "name": "Stereo Width",
        "internal_key": "Stereo Width",
        "value": f"{final_correlation*100:.0f}% corr | M/S: {final_ms_ratio:.2f} | L/R: {final_lr_balance:+.1f} dB",
        "correlation": final_correlation,
        "ms_ratio": round(final_ms_ratio, 2),
        "lr_balance_db": round(final_lr_balance, 1),
        "status": st_s,
        "message": msg_s
    }
    
    if stereo_temporal:
        stereo_metric["temporal_analysis"] = stereo_temporal
    
    metrics.append(stereo_metric)
    
    # 8. Frequency Balance (simplified - we don't have full frequency analysis in chunks)
    # Create dummy frequency balance data
    fb_dummy = {
        "low_percent": 33.0,
        "mid_percent": 34.0,
        "high_percent": 33.0,
        "low_db": 0.0,
        "mid_db": 0.0,
        "high_db": 0.0,
        "d_low_mid_db": 0.0,
        "d_high_mid_db": 0.0
    }
    st_f, msg_f, _ = status_freq(fb_dummy, genre, strict, lang)
    
    metrics.append({
        "name": "Frequency Balance",
        "internal_key": "Frequency Balance",
        "value": "Not analyzed in chunked mode",
        "status": "info",  # Always info for chunked
        "message": "An√°lisis de frecuencias no disponible en modo chunks." if lang == "es" else "Frequency analysis not available in chunked mode.",
        **fb_dummy
    })
    
    # Calculate score using the same score_report function as analyze_file
    hard_fail = tp_hard  # Use the hard fail from status_true_peak
    
    # Import and use the actual score_report function
    from analyzer import score_report
    score, verdict = score_report(metrics, hard_fail, strict, lang)
    
    # Build full result using the same structure as analyze_file
    result = {
        "file": {
            "name": path.name,
            "size": file_size,
            "duration": duration,
            "sample_rate": sr,
            "channels": channels
        },
        "technical": {
            "peak_dbfs": final_peak,
            "true_peak_dbtp": final_tp,
            "lufs": weighted_lufs,
            "plr": final_plr,
            "stereo_correlation": final_correlation,
            "lr_balance_db": final_lr_balance,
            "ms_ratio": final_ms_ratio
        },
        "metrics": metrics,
        "score": score,
        "verdict": verdict,
        "territory": territory,
        "is_mastered": is_mastered,
        "chunked": True,
        "num_chunks": num_chunks,
        "notes": {
            "lufs_is_real": True,
            "lufs_reliable": duration >= MIN_DURATION_FOR_LUFS,
            "oversample_factor": oversample,
            "auto_oversample": True,
            "clipping_detected": bool(results['clipping_chunks'])
        }
    }
    
    return result
def write_report(report: Dict[str, Any], strict: bool = False, lang: str = 'en', filename: str = "mix") -> str:
    """
    Generate narrative engineer-style feedback from analysis report.
    Perfect for emails, web UI, or written reports.
    Includes detection for already-mastered tracks.
    """
    lang = _pick_lang(lang)
    
    score = report.get("score", 0)
    verdict = report.get("verdict", "")
    metrics = report.get("metrics", [])
    notes = report.get("notes", {})
    
    # ============= MASTERED TRACK DETECTION =============
    # Detect if this is already a finished master (not suitable for mastering)
    lufs_metric = next((m for m in metrics if "LUFS" in m.get("internal_key", "")), None)
    peak_metric = next((m for m in metrics if "Headroom" in m.get("internal_key", "")), None)
    tp_metric = next((m for m in metrics if "True Peak" in m.get("internal_key", "")), None)
    
    # Extract numerical values
    lufs_value = None
    if lufs_metric and lufs_metric.get("value") != "N/A":
        try:
            # Extract LUFS value (e.g., "-12.1 LUFS" -> -12.1)
            lufs_str = lufs_metric.get("value", "")
            lufs_value = float(lufs_str.split()[0])
        except:
            pass
    
    peak_value = None
    if peak_metric:
        try:
            # Extract peak dBFS (e.g., "-0.1 dBFS" -> -0.1)
            peak_str = peak_metric.get("peak_db", "")
            peak_value = float(peak_str.replace(" dBFS", "").replace("dBFS", ""))
        except:
            pass
    
    tp_value = None
    if tp_metric:
        try:
            # Extract true peak dBTP (e.g., "-0.1 dBTP" -> -0.1)
            tp_str = tp_metric.get("value", "")
            tp_value = float(tp_str.replace(" dBTP", "").replace("dBTP", ""))
        except:
            pass
    
    # Detection criteria for mastered track:
    # 1. LUFS > -14 (commercial loudness level)
    # 2. AND (Peak > -1.0 dBFS OR True Peak > -1.0 dBTP)
    is_mastered = False
    if lufs_value is not None and lufs_value > -14:
        if (peak_value is not None and peak_value > -1.0) or (tp_value is not None and tp_value > -1.0):
            is_mastered = True
    
    # If mastered track detected, build comprehensive master analysis message
    if is_mastered:
        # Extract all metrics for comprehensive analysis
        plr_metric = next((m for m in metrics if "PLR" in m.get("internal_key", "")), None)
        stereo_metric = next((m for m in metrics if "Stereo" in m.get("internal_key", "")), None)
        freq_metric = next((m for m in metrics if "Frequency" in m.get("internal_key", "")), None)
        
        # Check for clipping (actual sample clipping)
        clipping_detected = notes.get("clipping_detected", False)
        
        # Get temporal analysis for True Peak if available
        tp_temporal = None
        if tp_metric and "temporal_analysis" in tp_metric:
            tp_temporal = tp_metric["temporal_analysis"]
        
        if lang == 'es':
            headroom_str = f"{abs(peak_value):.1f} dB" if peak_value is not None else "0 dB"
            tp_str = f"{tp_value:.1f} dBTP" if tp_value is not None else "0.0 dBTP"
            lufs_str = f"{lufs_value:.1f} LUFS" if lufs_value is not None else "nivel comercial"
            
            # SECTION 1: Header + Detection Reason
            filename_ref = f"üéµ Sobre \"{filename}\"\n\n"
            message = (
                filename_ref +
                "üéØ Este archivo parece ser un m√°ster finalizado, no una mezcla para entregar a mastering.\n\n"
                "El an√°lisis muestra:\n"
                f"‚Ä¢ Loudness comercial ({lufs_str})\n"
                f"‚Ä¢ Headroom muy reducido ({headroom_str})\n"
                f"‚Ä¢ True Peak que excede el l√≠mite digital ({tp_str})\n\n"
                "Estas caracter√≠sticas son normales en un master terminado, pero lo hacen inadecuado para procesarlo nuevamente en mastering.\n\n"
            )
            
            # SECTION 2: Positive Aspects
            positive_aspects = []
            
            # Check stereo correlation
            if stereo_metric:
                stereo_status = stereo_metric.get("status", "")
                stereo_value = stereo_metric.get("value")
                if stereo_status in ["perfect", "pass"]:
                    if isinstance(stereo_value, (int, float)):
                        positive_aspects.append(f"‚Ä¢ Balance est√©reo: excelente correlaci√≥n ({stereo_value:.2f})")
                    else:
                        positive_aspects.append("‚Ä¢ Balance est√©reo: buena compatibilidad mono")
            
            # Check frequency balance
            if freq_metric:
                freq_status = freq_metric.get("status", "")
                if freq_status in ["perfect", "pass"]:
                    positive_aspects.append("‚Ä¢ Balance tonal: saludable")
            
            # Check PLR (if reasonable for a master)
            if plr_metric:
                plr_value = plr_metric.get("value")
                if isinstance(plr_value, (int, float)) and plr_value >= 7:
                    positive_aspects.append(f"‚Ä¢ Rango din√°mico: conservado ({plr_value:.1f} dB PLR)")
            
            if positive_aspects:
                message += "‚úÖ Aspectos t√©cnicamente correctos:\n"
                message += "\n".join(positive_aspects)
                message += "\n\n"
            
            # SECTION 2.5: Temporal Analysis (if available from chunked mode)
            has_temporal = False
            temporal_message = ""
            
            # Check for True Peak temporal analysis
            if tp_metric and "temporal_analysis" in tp_metric:
                tp_temporal_data = tp_metric["temporal_analysis"]
                num_regions = tp_temporal_data.get('num_regions', 0)
                percentage = tp_temporal_data.get('percentage_above_threshold', 0)
                regions = tp_temporal_data.get('regions', [])
                
                if num_regions > 0:
                    has_temporal = True
                    temporal_message += f"üîä True Peak: Presente durante {percentage:.0f}% del tiempo.\n"
                    temporal_message += f"   Regiones afectadas ({num_regions}):\n"
                    for region in regions[:3]:  # Max 3 regions
                        start_min = int(region['start'] // 60)
                        start_sec = int(region['start'] % 60)
                        end_min = int(region['end'] // 60)
                        end_sec = int(region['end'] % 60)
                        temporal_message += f"   ‚Ä¢ {start_min}:{start_sec:02d} ‚Üí {end_min}:{end_sec:02d}\n"
                    temporal_message += "\n"
                    temporal_message += "üí° El track est√° procesado a nivel de master con limitaci√≥n agresiva.\n\n"
            
            # Check for Stereo temporal analysis
            if stereo_metric and "temporal_analysis" in stereo_metric:
                temporal = stereo_metric["temporal_analysis"]
                
                # Correlation temporal
                if 'correlation' in temporal:
                    corr_data = temporal['correlation']
                    num_regions = corr_data.get('num_regions', 0)
                    regions = corr_data.get('regions', [])
                    
                    if num_regions > 0:
                        has_temporal = True
                        temporal_message += f"üéß Correlaci√≥n ({num_regions} regi√≥n{'es' if num_regions > 1 else ''} problem√°tica{'s' if num_regions > 1 else ''}):\n"
                        for region in regions[:3]:
                            start_min = int(region['start'] // 60)
                            start_sec = int(region['start'] % 60)
                            end_min = int(region['end'] // 60)
                            end_sec = int(region['end'] % 60)
                            dur = int(region['duration'])
                            corr = region['avg_correlation']
                            issue = region['issue']
                            
                            temporal_message += f"   ‚Ä¢ {start_min}:{start_sec:02d} ‚Üí {end_min}:{end_sec:02d} ({dur}s): "
                            if issue == 'low':
                                temporal_message += f"Correlaci√≥n baja ({corr*100:.0f}%)\n"
                            else:
                                temporal_message += f"Correlaci√≥n muy alta ({corr*100:.0f}%)\n"
                        temporal_message += "\n"
                
                # M/S Ratio temporal
                if 'ms_ratio' in temporal:
                    ms_data = temporal['ms_ratio']
                    num_regions = ms_data.get('num_regions', 0)
                    regions = ms_data.get('regions', [])
                    
                    if num_regions > 0:
                        has_temporal = True
                        temporal_message += f"üìê M/S Ratio ({num_regions} regi√≥n{'es' if num_regions > 1 else ''} problem√°tica{'s' if num_regions > 1 else ''}):\n"
                        for region in regions[:3]:
                            start_min = int(region['start'] // 60)
                            start_sec = int(region['start'] % 60)
                            end_min = int(region['end'] // 60)
                            end_sec = int(region['end'] % 60)
                            dur = int(region['duration'])
                            ms = region['avg_ms_ratio']
                            issue = region['issue']
                            
                            temporal_message += f"   ‚Ä¢ {start_min}:{start_sec:02d} ‚Üí {end_min}:{end_sec:02d} ({dur}s): "
                            if issue == 'mono':
                                temporal_message += f"Ratio bajo ({ms:.2f})\n"
                            else:
                                temporal_message += f"Ratio alto ({ms:.2f})\n"
                        temporal_message += "\n"
                
                # L/R Balance temporal
                if 'lr_balance' in temporal:
                    lr_data = temporal['lr_balance']
                    num_regions = lr_data.get('num_regions', 0)
                    regions = lr_data.get('regions', [])
                    
                    if num_regions > 0:
                        has_temporal = True
                        temporal_message += f"‚öñÔ∏è Balance L/R ({num_regions} regi√≥n{'es' if num_regions > 1 else ''} problem√°tica{'s' if num_regions > 1 else ''}):\n"
                        for region in regions[:3]:
                            start_min = int(region['start'] // 60)
                            start_sec = int(region['start'] % 60)
                            end_min = int(region['end'] // 60)
                            end_sec = int(region['end'] % 60)
                            dur = int(region['duration'])
                            balance = region['avg_balance_db']
                            side = region['side']
                            
                            temporal_message += f"   ‚Ä¢ {start_min}:{start_sec:02d} ‚Üí {end_min}:{end_sec:02d} ({dur}s): "
                            if side == 'left':
                                temporal_message += f"Desbalance L: +{abs(balance):.1f} dB\n"
                            else:
                                temporal_message += f"Desbalance R: {balance:.1f} dB\n"
                        temporal_message += "\n"
            
            # Add temporal analysis section if there's any temporal data
            if has_temporal:
                message += "‚ö†Ô∏è AN√ÅLISIS TEMPORAL:\n\n"
                message += temporal_message
            
            # SECTION 3: Technical Observations
            observations = []
            
            # PLR observation (over-compression)
            if plr_metric:
                plr_value = plr_metric.get("value")
                if isinstance(plr_value, (int, float)) and plr_value < 7:
                    observations.append(
                        f"‚Ä¢ PLR: {plr_value:.1f} dB - din√°micas muy reducidas por limiting agresivo.\n"
                        "  Normal en masters comerciales loud, pero reduce micro-din√°mica."
                    )
            
            # Frequency balance observation
            if freq_metric:
                freq_status = freq_metric.get("status", "")
                if freq_status == "warning":
                    freq_msg = freq_metric.get("message", "")
                    observations.append(
                        f"‚Ä¢ Balance tonal: {freq_msg}\n"
                        "  Puede ser decisi√≥n creativa, pero verifica traducci√≥n en m√∫ltiples sistemas."
                    )
            
            # Stereo correlation observation
            if stereo_metric:
                stereo_value = stereo_metric.get("value")
                stereo_status = stereo_metric.get("status", "")
                if isinstance(stereo_value, (int, float)) and stereo_value < 0.60:
                    observations.append(
                        f"‚Ä¢ Ancho est√©reo muy amplio (correlaci√≥n {stereo_value:.2f}).\n"
                        "  Verifica compatibilidad en reproducci√≥n mono y sistemas Bluetooth."
                    )
            
            if observations:
                message += "üìä Observaciones t√©cnicas del master:\n"
                message += "\n".join(observations)
                message += "\n\n"
                message += "üí° Estas observaciones NO invalidan el master, solo contextualizan las decisiones t√©cnicas tomadas durante el proceso.\n\n"
            
            # SECTION 4: Bifurcation - If Mix
            # Calculate how much to reduce (correct formula)
            target_peak_dbfs = -6.0
            if peak_value is not None:
                reduction_needed = max(0.0, peak_value - target_peak_dbfs)
                reduction_rounded = round(reduction_needed)
            else:
                reduction_rounded = 6
            
            message += (
                "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
                "‚ö†Ô∏è SI ESTE ARCHIVO CORRESPONDE A UNA MEZCLA:\n"
                "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\n"
                "Si tu intenci√≥n es enviarla a mastering, vuelve a la sesi√≥n original sin limitaci√≥n "
                "en el bus maestro y ajusta el nivel antes del bounce:\n\n"
                "1. Vuelve a tu sesi√≥n de mezcla\n"
                "2. Inserta un plugin de Gain/Utility al final del bus master (DESPU√âS de toda tu cadena)\n"
                f"3. Reduce el nivel aproximadamente {reduction_rounded} dB\n"
                "4. Verifica que los picos queden alrededor de -6 dBFS\n"
                "5. Re-exporta\n\n"
                "Esto le devuelve al mastering el espacio necesario para trabajar sin distorsi√≥n.\n\n"
            )
            
            # SECTION 5: Bifurcation - If Master
            message += (
                "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
                "‚úÖ SI ESTE ES TU MASTER FINAL:\n"
                "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\n"
            )
            
            if tp_value is not None and tp_value > -1.0:
                message += (
                    f"üîß True Peak: {tp_str}\n\n"
                    "üìã Lo que recomiendan las plataformas: ‚â§ -1.0 dBTP\n\n"
                    "üìä Lo que hace la industria real:\n"
                    "Muchos masters comerciales loud (EDM, pop, trap, reggaeton) est√°n entre -0.3 y +0.5 dBTP. "
                    "Los algoritmos de normalizaci√≥n modernos lo toleran bien.\n\n"
                    "üí° Tu decisi√≥n:\n"
                    "Si tu master traduce bien en diferentes sistemas y suena como buscas, el archivo es "
                    "funcional para distribuci√≥n. El riesgo de clipping intersample es bajo en codecs modernos.\n\n"
                    "Si prefieres m√°xima seguridad t√©cnica: reduce 1‚Äì2 dB con Gain/Utility al final de la cadena "
                    "y re-exporta.\n\n"
                    "üéß Al final del d√≠a, tus o√≠dos tienen la √∫ltima palabra. Si el master suena balanceado, "
                    "impactante y se traduce bien en m√∫ltiples sistemas, conf√≠a en tu decisi√≥n."
                )
            else:
                message += "El archivo est√° listo para distribuci√≥n."
            
            return message
            
        else:  # English
            headroom_str = f"{abs(peak_value):.1f} dB" if peak_value is not None else "0 dB"
            tp_str = f"{tp_value:.1f} dBTP" if tp_value is not None else "0.0 dBTP"
            lufs_str = f"{lufs_value:.1f} LUFS" if lufs_value is not None else "commercial level"
            
            # SECTION 1: Header + Detection Reason
            filename_ref = f"üéµ Regarding \"{filename}\"\n\n"
            message = (
                filename_ref +
                "üéØ This file appears to be a finished master, not a mix prepared for mastering delivery.\n\n"
                "The analysis shows:\n"
                f"‚Ä¢ Commercial loudness level ({lufs_str})\n"
                f"‚Ä¢ Very reduced headroom ({headroom_str})\n"
                f"‚Ä¢ True peak exceeding digital ceiling ({tp_str})\n\n"
                "These characteristics are normal in a finished master, but make it unsuitable for additional mastering processing.\n\n"
            )
            
            # SECTION 2: Positive Aspects
            positive_aspects = []
            
            # Check stereo correlation
            if stereo_metric:
                stereo_status = stereo_metric.get("status", "")
                stereo_value = stereo_metric.get("value")
                if stereo_status in ["perfect", "pass"]:
                    if isinstance(stereo_value, (int, float)):
                        positive_aspects.append(f"‚Ä¢ Stereo balance: excellent correlation ({stereo_value:.2f})")
                    else:
                        positive_aspects.append("‚Ä¢ Stereo balance: good mono compatibility")
            
            # Check frequency balance
            if freq_metric:
                freq_status = freq_metric.get("status", "")
                if freq_status in ["perfect", "pass"]:
                    positive_aspects.append("‚Ä¢ Tonal balance: healthy")
            
            # Check PLR (if reasonable for a master)
            if plr_metric:
                plr_value = plr_metric.get("value")
                if isinstance(plr_value, (int, float)) and plr_value >= 7:
                    positive_aspects.append(f"‚Ä¢ Dynamic range: preserved ({plr_value:.1f} dB PLR)")
            
            if positive_aspects:
                message += "‚úÖ Technically correct aspects:\n"
                message += "\n".join(positive_aspects)
                message += "\n\n"
            
            # SECTION 3: Technical Observations
            observations = []
            
            # PLR observation (over-compression)
            if plr_metric:
                plr_value = plr_metric.get("value")
                if isinstance(plr_value, (int, float)) and plr_value < 7:
                    observations.append(
                        f"‚Ä¢ PLR: {plr_value:.1f} dB - dynamics heavily reduced by aggressive limiting.\n"
                        "  Normal in loud commercial masters, but reduces micro-dynamics."
                    )
            
            # Frequency balance observation
            if freq_metric:
                freq_status = freq_metric.get("status", "")
                if freq_status == "warning":
                    freq_msg = freq_metric.get("message", "")
                    observations.append(
                        f"‚Ä¢ Tonal balance: {freq_msg}\n"
                        "  May be a creative decision, but verify translation across systems."
                    )
            
            # Stereo correlation observation
            if stereo_metric:
                stereo_value = stereo_metric.get("value")
                stereo_status = stereo_metric.get("status", "")
                if isinstance(stereo_value, (int, float)) and stereo_value < 0.60:
                    observations.append(
                        f"‚Ä¢ Very wide stereo field (correlation {stereo_value:.2f}).\n"
                        "  Check mono playback compatibility and Bluetooth systems."
                    )
            
            if observations:
                message += "üìä Technical observations of this master:\n"
                message += "\n".join(observations)
                message += "\n\n"
                message += "üí° These observations do NOT invalidate the master‚Äîthey simply contextualize the technical decisions made during the process.\n\n"
            
            # SECTION 4: Bifurcation - If Mix
            # Calculate how much to reduce (correct formula)
            target_peak_dbfs = -6.0
            if peak_value is not None:
                reduction_needed = max(0.0, peak_value - target_peak_dbfs)
                reduction_rounded = round(reduction_needed)
            else:
                reduction_rounded = 6
            
            message += (
                "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
                "‚ö†Ô∏è IF THIS FILE IS INTENDED TO BE A MIX:\n"
                "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\n"
                "If your intention is to send it to mastering, go back to the original session without "
                "bus limiting and adjust the level before bouncing:\n\n"
                "1. Return to your mix session\n"
                "2. Insert a Gain/Utility plugin at the end of your master bus (AFTER all processing)\n"
                f"3. Lower the level by approximately {reduction_rounded} dB\n"
                "4. Verify peaks land around -6 dBFS\n"
                "5. Re-export\n\n"
                "This restores the headroom needed for proper mastering without distortion.\n\n"
            )
            
            # SECTION 5: Bifurcation - If Master
            message += (
                "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
                "‚úÖ IF THIS IS YOUR FINAL MASTER:\n"
                "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\n"
            )
            
            if tp_value is not None and tp_value > -1.0:
                message += (
                    f"üîß True Peak: {tp_str}\n\n"
                    "üìã What platforms recommend: ‚â§ -1.0 dBTP\n\n"
                    "üìä What the industry actually does:\n"
                    "Many loud commercial masters (EDM, pop, trap, reggaeton) sit between -0.3 and +0.5 dBTP. "
                    "Modern normalization algorithms handle this well.\n\n"
                    "üí° Your decision:\n"
                    "If your master translates well across systems and sounds the way you want, the file is "
                    "functional for distribution. The risk of intersample clipping is low in modern codecs.\n\n"
                    "If you prefer maximum technical safety: lower by 1‚Äì2 dB with a Gain/Utility plugin at the "
                    "end of your chain and re-export.\n\n"
                    "üéß At the end of the day, your ears have the final say. If the master sounds balanced, "
                    "impactful, and translates well across systems, trust your decision."
                )
            else:
                message += "The file is ready for distribution."
            
            return message
    
    # ============= NORMAL MIX PROCESSING (NOT MASTERED) =============
    # Count issues by severity
    critical_issues = [f"{m['name']}: {m['message']}" for m in metrics if m.get("status") == "critical"]
    warnings = [f"{m['name']}: {m['message']}" for m in metrics if m.get("status") == "warning"]
    
    # Build narrative based on score and issues
    if lang == 'es':
        # Spanish narrative
        if score >= 95:
            intro = "Tu mezcla est√° en un estado excelente para mastering."
        elif score >= 85:
            intro = "Tu mezcla est√° en muy buen punto para mastering."
        elif score >= 75:
            intro = "Tu mezcla est√° lista para mastering, aunque hay algunos puntos menores que podr√≠as revisar."
        elif score >= 60:
            intro = "Tu mezcla necesita algunos ajustes antes de enviarla a mastering."
        else:
            intro = "Tu mezcla requiere atenci√≥n en varios aspectos t√©cnicos antes del mastering."
        
        # Technical assessment
        tech_parts = []
        
        # Headroom & True Peak
        headroom_metric = next((m for m in metrics if "Headroom" in m.get("internal_key", "")), None)
        truepeak_metric = next((m for m in metrics if "True Peak" in m.get("internal_key", "")), None)
        
        if headroom_metric and headroom_metric.get("status") in ["perfect", "pass"]:
            tech_parts.append("Headroom apropiado")
        elif headroom_metric and headroom_metric.get("status") == "warning":
            tech_parts.append("Headroom un poco ajustado")
        elif headroom_metric and headroom_metric.get("status") == "critical":
            tech_parts.append("Headroom insuficiente (riesgo de clipping)")
        
        # PLR / Dynamics
        plr_metric = next((m for m in metrics if "PLR" in m.get("internal_key", "")), None)
        if plr_metric and plr_metric.get("value") != "N/A":
            if plr_metric.get("status") in ["perfect", "pass"]:
                tech_parts.append("Excelente rango din√°mico")
            elif plr_metric.get("status") == "warning":
                tech_parts.append("Rango din√°mico algo comprimido")
        
        # Stereo
        stereo_metric = next((m for m in metrics if "Stereo" in m.get("internal_key", "")), None)
        if stereo_metric and stereo_metric.get("status") in ["perfect", "pass"]:
            tech_parts.append("Imagen est√©reo s√≥lida y bien centrada")
        elif stereo_metric and stereo_metric.get("status") == "warning":
            tech_parts.append("Algunas inconsistencias de fase en imagen est√©reo")
        
        # Frequency Balance
        freq_metric = next((m for m in metrics if "Frequency" in m.get("internal_key", "")), None)
        if freq_metric and freq_metric.get("status") in ["perfect", "pass"]:
            tech_parts.append("Balance tonal generalmente saludable")
        elif freq_metric and freq_metric.get("status") == "warning":
            tech_parts.append("Balance tonal que podr√≠a mejorarse")
        
        tech_assessment = ", ".join(tech_parts) if tech_parts else "caracter√≠sticas t√©cnicas aceptables"
        
        # Construir frase de manera correcta
        if tech_parts:
            tech_sentence = f"En general, la mezcla presenta:\n- " + "\n- ".join(tech_parts)
        else:
            tech_sentence = "La mezcla tiene caracter√≠sticas t√©cnicas aceptables."
        
        # Issues summary with EXPLICIT list of ALL problems
        if critical_issues:
            issues_list = "\n".join([f"   ‚Ä¢ {issue}" for issue in critical_issues])
            issues_sentence = f"\n\n‚ö†Ô∏è Se detectaron {len(critical_issues)} problema(s) cr√≠tico(s) que requieren atenci√≥n inmediata:\n{issues_list}"
        elif warnings:
            # FIXED: Listar expl√≠citamente los warnings con contexto
            issues_details = []
            
            # Construir lista detallada de warnings
            for m in metrics:
                if m.get("status") == "warning":
                    metric_name = m.get("name", "M√©trica")
                    metric_value = m.get("value")
                    internal_key = m.get("internal_key", "")
                    
                    # Headroom warning
                    if "Headroom" in internal_key:
                        # metric_value already includes unit (e.g., "-2.5 dBFS")
                        peak_val = str(metric_value) if not isinstance(metric_value, (int, float)) else f"{metric_value:.1f} dBFS"
                        issues_details.append(
                            f"‚Ä¢ **Headroom general**: los picos est√°n alrededor de {peak_val}. "
                            f"Para un margen √≥ptimo en mastering, ideal entre -6 y -4 dBFS."
                        )
                    
                    # True Peak warning
                    elif "True Peak" in internal_key:
                        # metric_value already includes unit (e.g., "-2.3 dBTP")
                        tp_val = str(metric_value) if not isinstance(metric_value, (int, float)) else f"{metric_value:.1f} dBTP"
                        issues_details.append(
                            f"‚Ä¢ **True Peak**: est√° en {tp_val}. Para m√°xima seguridad en "
                            f"conversiones de formato, se recomienda ‚â§-3.0 dBTP."
                        )
                    
                    # PLR warning
                    elif "PLR" in internal_key:
                        plr_val = f"{metric_value:.1f}" if isinstance(metric_value, (int, float)) else str(metric_value)
                        issues_details.append(
                            f"‚Ä¢ **Rango Din√°mico (PLR)**: est√° en {plr_val} dB. "
                            f"Para m√°xima flexibilidad en mastering, ideal 12-14 dB en modo strict."
                        )
                    
                    # Stereo warning
                    elif "Stereo" in internal_key or "Ancho" in internal_key:
                        corr_val = f"{metric_value:.2f}" if isinstance(metric_value, (int, float)) else str(metric_value)
                        issues_details.append(
                            f"‚Ä¢ **Campo Est√©reo**: correlaci√≥n {corr_val}. "
                            f"Revisar compatibilidad mono y balance L/R."
                        )
                    
                    # Frequency Balance warning
                    elif "Frequency" in internal_key or "Balance" in internal_key:
                        issues_details.append(
                            f"‚Ä¢ **Balance Tonal**: revisar distribuci√≥n de frecuencias "
                            f"(graves, medios, agudos)."
                        )
            
            if issues_details:
                issues_list_formatted = "\n".join(issues_details)
                scope_note = "\n\nüìç **Alcance**: Estos puntos afectan a todo el track, no a secciones espec√≠ficas." if strict else ""
                issues_sentence = f"\n\nüìã **Puntos a revisar** (no cr√≠ticos):\n{issues_list_formatted}{scope_note}"
            else:
                issues_sentence = f"\n\nüìã Hay {len(warnings)} punto(s) que podr√≠as revisar, aunque no son cr√≠ticos para el mastering."
        else:
            issues_sentence = "\n\n‚úÖ No se detectaron problemas t√©cnicos cr√≠ticos."
        
        # Stereo Field Detailed Section (ONLY if issues detected)
        stereo_detail = ""
        if stereo_metric:
            ms_ratio = stereo_metric.get("ms_ratio", 0)
            lr_balance = stereo_metric.get("lr_balance_db", 0)
            
            # Show detailed section ONLY if there are stereo issues
            has_stereo_issue = False
            stereo_issues = []
            
            # Check M/S Ratio issues
            if ms_ratio < 0.05:
                has_stereo_issue = True
                stereo_issues.append(
                    "‚ö†Ô∏è La mezcla no tiene informaci√≥n est√©reo (pr√°cticamente mono).\n\n"
                    "   ü§î ¬øEs esto intencional?\n\n"
                    "   Si S√ç es intencional:\n"
                    "   ‚Ä¢ Perfecto - algunas producciones vintage o art√≠sticas usan mono\n"
                    "   ‚Ä¢ Solo confirma que sea la decisi√≥n correcta\n\n"
                    "   Si NO es intencional, verifica:\n"
                    "   ‚Ä¢ ¬øExportaste en mono por error? Revisa configuraci√≥n de bounce\n"
                    "   ‚Ä¢ ¬øTienes routing mal configurado en el DAW?\n"
                    "   ‚Ä¢ ¬øTodos los elementos est√°n centrados sin paneo?\n\n"
                    "   üí° Para mastering:\n"
                    "   Si fue error, re-exporta en est√©reo para aprovechar el paneo\n"
                    "   y espacializaci√≥n que dise√±aste en la mezcla."
                )
            elif ms_ratio > 1.5:
                has_stereo_issue = True
                stereo_issues.append(
                    f"‚ö†Ô∏è La informaci√≥n est√©reo es muy amplia (M/S Ratio: {ms_ratio:.2f}).\n\n"
                    "   Esto puede sonar impresionante en auriculares pero d√©bil en parlantes\n"
                    "   o sistemas mono (Bluetooth, tel√©fonos, algunos clubes).\n\n"
                    "   üîç Causas comunes:\n"
                    "   ‚Ä¢ Demasiados plugins de ensanchamiento est√©reo\n"
                    "   ‚Ä¢ Exceso de reverb/delay en los sides\n"
                    "   ‚Ä¢ Efectos est√©reo muy agresivos\n\n"
                    "   üí° C√≥mo corregirlo:\n"
                    "   1. Reduce o quita plugins de 'stereo widening'\n"
                    "   2. Baja el nivel de reverbs y delays panoramizados\n"
                    "   3. Trae elementos importantes m√°s al centro\n"
                    "   4. Prueba la mezcla en MONO - si pierde mucho cuerpo, est√° muy ancha"
                )
            
            # Check L/R Balance issues
            if abs(lr_balance) > 3.0:
                has_stereo_issue = True
                side = "izquierdo" if lr_balance > 0 else "derecho"
                stereo_issues.append(
                    f"‚ö†Ô∏è La mezcla tiene m√°s energ√≠a en el canal {side}\n"
                    f"   ({abs(lr_balance):.1f} dB de diferencia).\n\n"
                    "   ü§î ¬øEs intencional?\n\n"
                    "   Si S√ç (efecto art√≠stico):\n"
                    "   ‚Ä¢ Algunos productores usan paneo asim√©trico intencionalmente\n"
                    "   ‚Ä¢ Si es tu visi√≥n creativa, adelante\n\n"
                    "   Si NO es intencional:\n"
                    "   ‚Ä¢ Revisa el paneo general - puede haber demasiados elementos en un lado\n"
                    "   ‚Ä¢ Verifica que no haya un canal con volumen incorrecto\n"
                    "   ‚Ä¢ Chequea plugins que puedan estar afectando el balance\n"
                    "   ‚Ä¢ Usa un medidor de fase/balance en el master para monitorear\n\n"
                    "   üí° Recomendaci√≥n:\n"
                    "   Prueba la mezcla en diferentes sistemas (auriculares, parlantes, mono)\n"
                    "   para confirmar que el desbalance funciona musicalmente."
                )
            
            # Add stereo detail section if issues found
            if has_stereo_issue:
                stereo_detail = "\n\nüìä CAMPO EST√âREO - An√°lisis Detallado:\n" + "\n\n".join(stereo_issues)
        
        # Recommendation
        if score >= 85:
            # Add technical details for high-scoring mixes
            tech_details = build_technical_details(metrics, lang)
            
            if strict:
                recommendation = "\n\nüí° Recomendaci√≥n: Esta mezcla cumple con los est√°ndares profesionales para entrega comercial. Puedes enviarla a mastering con confianza."
            else:
                recommendation = "\n\nüí° Recomendaci√≥n: Env√≠ala a mastering tal como est√°."
        elif score >= 75:
            tech_details = ""
            recommendation = "\n\nüí° Recomendaci√≥n: Revisa los puntos mencionados si buscas la m√°xima calidad, pero la mezcla es aceptable para mastering."
        else:
            tech_details = ""
            recommendation = "\n\nüí° Recomendaci√≥n: Atiende los problemas identificados antes de enviar a mastering para obtener los mejores resultados."
        
        # Mode note
        if strict:
            mode_note = "\n\nüìä An√°lisis realizado con est√°ndares comerciales estrictos (modo strict)."
        else:
            mode_note = ""
        
        # Add filename reference at the beginning (natural narrative style)
        filename_ref = f"üéµ Sobre \"{filename}\"\n\n"
        
        # Generate CTA based on score
        cta = generate_cta(score, strict, lang, mode="write")
        
        return f"{filename_ref}{intro}\n\n{tech_sentence}{issues_sentence}{stereo_detail}{tech_details}{recommendation}{mode_note}{cta}"
    
    else:
        # English narrative
        if score >= 95:
            intro = "Your mix is in excellent shape for mastering."
        elif score >= 85:
            intro = "Your mix is in very good shape for mastering."
        elif score >= 75:
            intro = "Your mix is ready for mastering, though there are a few minor points you could review."
        elif score >= 60:
            intro = "Your mix needs some adjustments before sending to mastering."
        else:
            intro = "Your mix requires attention to several technical aspects before mastering."
        
        # Technical assessment
        tech_parts = []
        
        # Headroom & True Peak
        headroom_metric = next((m for m in metrics if "Headroom" in m.get("internal_key", "")), None)
        truepeak_metric = next((m for m in metrics if "True Peak" in m.get("internal_key", "")), None)
        
        if headroom_metric and headroom_metric.get("status") in ["perfect", "pass"]:
            tech_parts.append("appropriate headroom")
        elif headroom_metric and headroom_metric.get("status") == "warning":
            tech_parts.append("slightly tight headroom")
        elif headroom_metric and headroom_metric.get("status") == "critical":
            tech_parts.append("insufficient headroom (clipping risk)")
        
        # PLR / Dynamics
        plr_metric = next((m for m in metrics if "PLR" in m.get("internal_key", "")), None)
        if plr_metric and plr_metric.get("value") != "N/A":
            if plr_metric.get("status") in ["perfect", "pass"]:
                tech_parts.append("excellent dynamic range")
            elif plr_metric.get("status") == "warning":
                tech_parts.append("somewhat compressed dynamic range")
        
        # Stereo
        stereo_metric = next((m for m in metrics if "Stereo" in m.get("internal_key", "")), None)
        if stereo_metric and stereo_metric.get("status") in ["perfect", "pass"]:
            tech_parts.append("a solid, well-centered stereo image")
        elif stereo_metric and stereo_metric.get("status") == "warning":
            tech_parts.append("some phase inconsistencies in stereo image")
        
        # Frequency Balance
        freq_metric = next((m for m in metrics if "Frequency" in m.get("internal_key", "")), None)
        if freq_metric and freq_metric.get("status") in ["perfect", "pass"]:
            tech_parts.append("generally healthy tonal balance")
        elif freq_metric and freq_metric.get("status") == "warning":
            tech_parts.append("tonal balance with room for improvement")
        
        tech_assessment = ", ".join(tech_parts) if tech_parts else "acceptable technical characteristics"
        
        # Construir frase de manera correcta
        if tech_parts:
            tech_sentence = f"Overall, the mix shows:\n- " + "\n- ".join([part.capitalize() for part in tech_parts])
        else:
            tech_sentence = "The mix has acceptable technical characteristics."
        
        # Issues summary with EXPLICIT list of ALL problems
        if critical_issues:
            issues_list = "\n".join([f"   ‚Ä¢ {issue}" for issue in critical_issues])
            issues_sentence = f"\n\n‚ö†Ô∏è {len(critical_issues)} critical issue(s) detected that require immediate attention:\n{issues_list}"
        elif warnings:
            # FIXED: List warnings explicitly with context
            issues_details = []
            
            # Build detailed warnings list
            for m in metrics:
                if m.get("status") == "warning":
                    metric_name = m.get("name", "Metric")
                    metric_value = m.get("value")
                    internal_key = m.get("internal_key", "")
                    
                    # Headroom warning
                    if "Headroom" in internal_key:
                        # metric_value already includes unit (e.g., "-2.5 dBFS")
                        peak_val = str(metric_value) if not isinstance(metric_value, (int, float)) else f"{metric_value:.1f} dBFS"
                        issues_details.append(
                            f"‚Ä¢ **Overall headroom**: peak levels sit around {peak_val}. "
                            f"For optimal mastering flexibility, peaks closer to -6 to -4 dBFS are recommended."
                        )
                    
                    # True Peak warning
                    elif "True Peak" in internal_key:
                        # metric_value already includes unit (e.g., "-2.3 dBTP")
                        tp_val = str(metric_value) if not isinstance(metric_value, (int, float)) else f"{metric_value:.1f} dBTP"
                        issues_details.append(
                            f"‚Ä¢ **True Peak**: currently at {tp_val}. For maximum safety in "
                            f"format conversions, ‚â§-3.0 dBTP is recommended."
                        )
                    
                    # PLR warning
                    elif "PLR" in internal_key:
                        plr_val = f"{metric_value:.1f}" if isinstance(metric_value, (int, float)) else str(metric_value)
                        issues_details.append(
                            f"‚Ä¢ **Dynamic Range (PLR)**: currently at {plr_val} dB. "
                            f"For maximum mastering flexibility, 12-14 dB is ideal in strict mode."
                        )
                    
                    # Stereo warning
                    elif "Stereo" in internal_key or "Width" in internal_key:
                        corr_val = f"{metric_value:.2f}" if isinstance(metric_value, (int, float)) else str(metric_value)
                        issues_details.append(
                            f"‚Ä¢ **Stereo Field**: correlation {corr_val}. "
                            f"Review mono compatibility and L/R balance."
                        )
                    
                    # Frequency Balance warning
                    elif "Frequency" in internal_key or "Balance" in internal_key:
                        issues_details.append(
                            f"‚Ä¢ **Tonal Balance**: review frequency distribution "
                            f"(lows, mids, highs)."
                        )
            
            if issues_details:
                issues_list_formatted = "\n".join(issues_details)
                scope_note = "\n\nüìç **Scope**: These points apply to the entire track, not specific sections." if strict else ""
                issues_sentence = f"\n\nüìã **Points to review** (non-critical):\n{issues_list_formatted}{scope_note}"
            else:
                issues_sentence = f"\n\nüìã There are {len(warnings)} point(s) you could review, though they're not critical for mastering."
        else:
            issues_sentence = "\n\n‚úÖ No critical technical issues detected."
        
        # Stereo Field Detailed Section (ONLY if issues detected)
        stereo_detail = ""
        if stereo_metric:
            ms_ratio = stereo_metric.get("ms_ratio", 0)
            lr_balance = stereo_metric.get("lr_balance_db", 0)
            
            # Show detailed section ONLY if there are stereo issues
            has_stereo_issue = False
            stereo_issues = []
            
            # Check M/S Ratio issues
            if ms_ratio < 0.05:
                has_stereo_issue = True
                stereo_issues.append(
                    "‚ö†Ô∏è Mix has no stereo information (practically mono).\n\n"
                    "   ü§î Is this intentional?\n\n"
                    "   If YES, it's intentional:\n"
                    "   ‚Ä¢ Perfect - some vintage or artistic productions use mono\n"
                    "   ‚Ä¢ Just confirm it's the right decision for your project\n\n"
                    "   If NOT intentional, check:\n"
                    "   ‚Ä¢ Did you export in mono by mistake? Review bounce settings\n"
                    "   ‚Ä¢ Is your DAW routing misconfigured?\n"
                    "   ‚Ä¢ Are all elements completely centered with no panning?\n\n"
                    "   üí° For mastering:\n"
                    "   If it was an error, re-export in stereo to take advantage of all\n"
                    "   the panning and spatialization you designed in your mix."
                )
            elif ms_ratio > 1.5:
                has_stereo_issue = True
                stereo_issues.append(
                    f"‚ö†Ô∏è Stereo information is very wide (M/S Ratio: {ms_ratio:.2f}).\n\n"
                    "   This may sound impressive on headphones but weak on speakers or\n"
                    "   mono systems (Bluetooth, phones, some clubs).\n\n"
                    "   üîç Common causes:\n"
                    "   ‚Ä¢ Too many stereo widening plugins\n"
                    "   ‚Ä¢ Excessive reverb/delay on the sides\n"
                    "   ‚Ä¢ Very aggressive stereo effects\n\n"
                    "   üí° How to fix it:\n"
                    "   1. Reduce or remove 'stereo widening' plugins\n"
                    "   2. Lower the level of panned reverbs and delays\n"
                    "   3. Bring important elements more to the center\n"
                    "   4. Test the mix in MONO - if it loses a lot of body, it's too wide"
                )
            
            # Check L/R Balance issues
            if abs(lr_balance) > 3.0:
                has_stereo_issue = True
                side = "left" if lr_balance > 0 else "right"
                stereo_issues.append(
                    f"‚ö†Ô∏è Mix has more energy in the {side} channel\n"
                    f"   ({abs(lr_balance):.1f} dB difference).\n\n"
                    "   ü§î Is this intentional?\n\n"
                    "   If YES (artistic effect):\n"
                    "   ‚Ä¢ Some producers use asymmetric panning intentionally\n"
                    "   ‚Ä¢ If it's your creative vision, go ahead\n\n"
                    "   If NOT intentional:\n"
                    "   ‚Ä¢ Check overall panning - there may be too many elements on one side\n"
                    "   ‚Ä¢ Verify that a channel doesn't have incorrect volume\n"
                    "   ‚Ä¢ Check plugins that might be affecting balance\n"
                    "   ‚Ä¢ Use a phase/balance meter on the master to monitor\n\n"
                    "   üí° Recommendation:\n"
                    "   Test the mix on different systems (headphones, speakers, mono)\n"
                    "   to confirm the imbalance works musically."
                )
            
            # Add stereo detail section if issues found
            if has_stereo_issue:
                stereo_detail = "\n\nüìä STEREO FIELD - Detailed Analysis:\n" + "\n\n".join(stereo_issues)
        
        # Recommendation
        if score >= 85:
            # Add technical details for high-scoring mixes
            tech_details = build_technical_details(metrics, lang)
            
            if strict:
                recommendation = "\n\nüí° Recommendation: This mix meets professional standards for commercial delivery. You can send it to mastering with confidence."
            else:
                recommendation = "\n\nüí° Recommendation: Send it to mastering as-is."
        elif score >= 75:
            tech_details = ""
            recommendation = "\n\nüí° Recommendation: Review the mentioned points if you're seeking maximum quality, but the mix is acceptable for mastering."
        else:
            tech_details = ""
            recommendation = "\n\nüí° Recommendation: Address the identified issues before sending to mastering for best results."
        
        # Mode note
        if strict:
            mode_note = "\n\nüìä Analysis performed with strict commercial delivery standards (strict mode)."
        else:
            mode_note = ""
        
        # Add filename reference at the beginning (natural narrative style)
        filename_ref = f"üéµ Regarding \"{filename}\"\n\n"
        
        # Generate CTA based on score
        cta = generate_cta(score, strict, lang, mode="write")
        
        return f"{filename_ref}{intro}\n\n{tech_sentence}{issues_sentence}{stereo_detail}{tech_details}{recommendation}{mode_note}{cta}"


def iter_audio_files(p: Path) -> List[Path]:
    """Itera archivos de audio en path o directorio."""
    exts = {".wav", ".aif", ".aiff", ".flac", ".mp3", ".ogg", ".m4a"}
    if p.is_file():
        return [p]
    files = []
    for f in sorted(p.glob("**/*")):
        if f.suffix.lower() in exts and f.is_file():
            files.append(f)
    return files


def generate_short_mode_report(report: Dict[str, Any], strict: bool = False, lang: str = 'en', filename: str = "") -> str:
    """
    Generate short mode report with bullets showing positive aspects and areas to improve.
    
    Structure:
    - Header (filename, score, verdict)
    - Positive aspects (bullets)
    - Areas to improve (bullets) 
    - Recommendation
    """
    lang = _pick_lang(lang)
    
    score = report.get("score", 0)
    verdict = report.get("verdict", "")
    metrics = report.get("metrics", [])
    
    # Build positive aspects list
    positive_aspects = []
    areas_to_improve = []
    
    for metric in metrics:
        status = metric.get("status", "")
        name = metric.get("name", "")
        message = metric.get("message", "")
        
        # Skip informational metrics
        if status == "info":
            continue
            
        # Add to appropriate list
        if status in ["perfect", "pass", "good"]:
            positive_aspects.append(f"‚Ä¢ {name}: {message}")
        elif status in ["warning", "critical", "catastrophic"]:
            areas_to_improve.append(f"‚Ä¢ {name}: {message}")
    
    # Build report
    if lang == 'es':
        header = ""
        if filename:
            header = f"üéµ Sobre \"{filename}\"\n\n"
        
        header += f"Puntuaci√≥n: {score}/100\n"
        header += f"Veredicto: {verdict}\n\n"
        
        body = ""
        
        if positive_aspects:
            body += "‚úÖ Aspectos Positivos:\n"
            body += "\n".join(positive_aspects[:5])  # Limit to 5
            body += "\n\n"
        
        if areas_to_improve:
            body += "‚ö†Ô∏è √Åreas a Mejorar:\n"
            body += "\n".join(areas_to_improve[:5])  # Limit to 5
            body += "\n\n"
        
        # Recommendation based on score
        if score >= 85:
            recommendation = "üí° Recomendaci√≥n: Env√≠ala a mastering tal como est√°."
        elif score >= 70:
            recommendation = "üí° Recomendaci√≥n: Con algunos ajustes menores, estar√° lista para mastering."
        elif score >= 50:
            recommendation = "üí° Recomendaci√≥n: Necesita varios ajustes antes de enviar a mastering."
        else:
            recommendation = "üí° Recomendaci√≥n: Requiere trabajo significativo antes de mastering."
        
        # Generate CTA
        cta = generate_cta(score, strict, lang, mode="short")
        
        return header + body + recommendation + "\n\n" + cta
    
    else:  # English
        header = ""
        if filename:
            header = f"üéµ Regarding \"{filename}\"\n\n"
        
        header += f"Score: {score}/100\n"
        header += f"Verdict: {verdict}\n\n"
        
        body = ""
        
        if positive_aspects:
            body += "‚úÖ Positive Aspects:\n"
            body += "\n".join(positive_aspects[:5])
            body += "\n\n"
        
        if areas_to_improve:
            body += "‚ö†Ô∏è Areas to Improve:\n"
            body += "\n".join(areas_to_improve[:5])
            body += "\n\n"
        
        # Recommendation based on score
        if score >= 85:
            recommendation = "üí° Recommendation: Send it to mastering as-is."
        elif score >= 70:
            recommendation = "üí° Recommendation: With minor adjustments, it'll be ready for mastering."
        elif score >= 50:
            recommendation = "üí° Recommendation: Needs several adjustments before sending to mastering."
        else:
            recommendation = "üí° Recommendation: Requires significant work before mastering."
        
        # Generate CTA
        cta = generate_cta(score, strict, lang, mode="short")
        
        return header + body + recommendation + "\n\n" + cta


# =============================================================================
# FUNCI√ìN 3: generate_visual_report - INSERTAR DESPU√âS DE generate_short_mode_report
# =============================================================================

def generate_visual_report(report: Dict[str, Any], strict: bool = False, lang: str = 'en', filename: str = "") -> str:
    """
    Generate visual mode report with bullets showing positive aspects and areas to review.
    Educational and constructive tone.
    """
    lang = _pick_lang(lang)
    
    metrics = report.get("metrics", [])
    
    # Build positive aspects and areas to review
    positive_aspects = []
    areas_to_review = []
    
    for metric in metrics:
        status = metric.get("status", "")
        name = metric.get("name", "")
        message = metric.get("message", "")
        
        # Skip informational metrics
        if status == "info":
            continue
            
        # Add to appropriate list with educational, positive framing
        if status in ["perfect", "pass", "good"]:
            # Extract the positive aspect concisely
            if "Headroom" in name:
                positive_aspects.append("Headroom apropiado para mastering" if lang == "es" else "Appropriate headroom for mastering")
            elif "True Peak" in name:
                positive_aspects.append("True Peak seguro para streaming" if lang == "es" else "Safe True Peak for streaming")
            elif "PLR" in name or "din√°m" in message.lower() or "dynamic" in message.lower():
                positive_aspects.append("Excelente rango din√°mico" if lang == "es" else "Excellent dynamic range")
            elif "Stereo" in name or "st√©reo" in name.lower():
                positive_aspects.append("Imagen est√©reo s√≥lida y centrada" if lang == "es" else "Solid and centered stereo image")
            elif "Frequency" in name or "Frecuen" in name:
                positive_aspects.append("Balance tonal saludable" if lang == "es" else "Healthy tonal balance")
            elif "LUFS" in name:
                positive_aspects.append("Nivel apropiado para mastering" if lang == "es" else "Appropriate level for mastering")
            elif "DC Offset" in name:
                positive_aspects.append("Sin DC offset detectado" if lang == "es" else "No DC offset detected")
        
        elif status in ["warning", "critical", "catastrophic"]:
            # Frame as "areas to review" with educational tone
            if "Headroom" in name:
                areas_to_review.append("Revisar headroom - Considerar dejar m√°s espacio en los picos" if lang == "es" else "Review headroom - Consider leaving more headroom in peaks")
            elif "True Peak" in name:
                areas_to_review.append("Revisar True Peak - Ajustar limitadores para evitar clipping" if lang == "es" else "Review True Peak - Adjust limiters to avoid clipping")
            elif "PLR" in name:
                areas_to_review.append("Revisar din√°mica - Considerar reducir compresi√≥n/limitaci√≥n" if lang == "es" else "Review dynamics - Consider reducing compression/limiting")
            elif "Stereo" in name or "st√©reo" in name.lower():
                areas_to_review.append("Revisar imagen est√©reo - Verificar balance y correlaci√≥n" if lang == "es" else "Review stereo image - Check balance and correlation")
            elif "Frequency" in name or "Frecuen" in name:
                areas_to_review.append("Revisar balance de frecuencias - Ajustar EQ si es necesario" if lang == "es" else "Review frequency balance - Adjust EQ if needed")
            elif "LUFS" in name:
                areas_to_review.append("Revisar nivel general - Ajustar gain staging" if lang == "es" else "Review overall level - Adjust gain staging")
    
    # Remove duplicates while preserving order
    positive_aspects = list(dict.fromkeys(positive_aspects))
    areas_to_review = list(dict.fromkeys(areas_to_review))
    
    # Build report
    if lang == 'es':
        # Add filename header if provided
        report_text = ""
        if filename:
            report_text = f"üéµ Sobre \"{filename}\"\n\n"
        
        if positive_aspects:
            report_text += "ASPECTOS POSITIVOS\n"
            report_text += "‚îÄ" * 50 + "\n"
            for aspect in positive_aspects[:6]:  # Limit to 6
                report_text += f"‚úì {aspect}\n"
            report_text += "\n"
        
        if areas_to_review:
            report_text += "ASPECTOS PARA REVISAR\n"
            report_text += "‚îÄ" * 50 + "\n"
            for aspect in areas_to_review[:6]:  # Limit to 6
                report_text += f"‚Üí {aspect}\n"
        
        return report_text.strip()
    
    else:  # English
        # Add filename header if provided
        report_text = ""
        if filename:
            report_text = f"üéµ Regarding \"{filename}\"\n\n"
        
        if positive_aspects:
            report_text += "POSITIVE ASPECTS\n"
            report_text += "‚îÄ" * 50 + "\n"
            for aspect in positive_aspects[:6]:
                report_text += f"‚úì {aspect}\n"
            report_text += "\n"
        
        if areas_to_review:
            report_text += "AREAS TO REVIEW\n"
            report_text += "‚îÄ" * 50 + "\n"
            for aspect in areas_to_review[:6]:
                report_text += f"‚Üí {aspect}\n"
        
        return report_text.strip()
def main() -> None:
    """Main entry point."""
    ap = argparse.ArgumentParser(
        description="Analyze mixes to verify they are ready for mastering delivery"
    )
    ap.add_argument("path", help="Archivo de audio o carpeta")
    ap.add_argument(
        "--oversample", 
        default="auto",
        help="Factor de sobremuestreo para true peak (default: auto, opciones: 1, 2, 4, auto)"
    )
    ap.add_argument(
        "--genre",
        choices=["rock", "pop", "edm", "electronic", "trap", "hip-hop", "jazz", "classical", "acoustic"],
        help="G√©nero musical para ajustar evaluaci√≥n de frecuencias (opcional)"
    )
    ap.add_argument(
        "--lang",
        choices=["en", "es"],
        default="en",
        help="Output language / Idioma de salida (en/es)"
    )

    ap.add_argument("--json", dest="json_path", default=None, help="Guardar reporte JSON")
    
    ap.add_argument(
        "--strict",
        action="store_true",
        help="Use stricter commercial-delivery thresholds (recommended for client/label delivery)."
    )
    ap.add_argument(
        "--notes-only",
        action="store_true",
        help="Print feedback without score/verdict (observations only)."
    )
    ap.add_argument(
        "--short",
        action="store_true",
        help="Short tips-only output (verdict + score + recommendations, no detailed metrics)."
    )
    ap.add_argument(
        "--write",
        action="store_true",
        help="Narrative written feedback (engineer-style paragraph, perfect for emails/reports)."
    )
    args = ap.parse_args()

    lang = _pick_lang(args.lang)

    # Parse oversample
    if args.oversample.lower() == "auto":
        oversample = 0  # se√±al para auto-detect
    else:
        try:
            oversample = int(args.oversample)
            if oversample not in [1, 2, 4]:
                raise ValueError
        except ValueError:
            print("‚ùå Error: --oversample debe ser 1, 2, 4 o 'auto'", file=sys.stderr)
            sys.exit(1)

    target = Path(args.path).expanduser()
    
    if not target.exists():
        print(f"‚ùå Error: No existe {target}", file=sys.stderr)
        sys.exit(1)
    
    files = iter_audio_files(target)
    
    if not files:
        print("‚ùå No audio files found / No se encontraron archivos de audio en la ruta indicada.", file=sys.stderr)
        sys.exit(1)

    reports = []
    for f in files:
        try:
            print(f"\n{UI_TEXT[lang]['analyzing']}: {f.name}...")
            report = analyze_file(f, oversample=oversample, genre=args.genre, strict=args.strict, lang=lang)
            reports.append(report)
        except Exception as e:
            print(f"‚ùå Error analyzing {f.name} / Error analizando {f.name}: {e}", file=sys.stderr)
            continue

    if not reports:
        print("‚ùå No se pudo analizar ning√∫n archivo", file=sys.stderr)
        sys.exit(1)

    # Build output (full vs notes-only)
    def _notes_only_view(r: dict) -> dict:
        out = {
            "file": r.get("file", {}),
            "issues": [],
            "notes": {},
        }
        for mtr in r.get("metrics", []) or []:
            if mtr.get("status") in ("warning", "critical"):
                out["issues"].append({
                    "name": mtr.get("name"),
                    "status": mtr.get("status"),
                    "value": mtr.get("value"),
                    "message": mtr.get("message"),
                })

        meta = r.get("notes", {}) or {}
        # Keep a few useful diagnostics (optional)
        for k in ("clipping_detected", "dc_offset_detected", "lufs_is_real", "lufs_reliable",
                  "oversample_factor", "auto_oversample"):
            if k in meta:
                out["notes"][k] = meta.get(k)

        out["mode"] = "strict" if args.strict else "normal"

        if not out["issues"]:
            if lang == 'es':
                out["summary"] = "‚úÖ No se detectaron problemas. Esta mezcla est√° lista para entrega a mastering."
            else:
                out["summary"] = "‚úÖ No issues detected. This mix is ready for mastering delivery."
        else:
            if lang == 'es':
                out["summary"] = f"‚ö†Ô∏è {len(out['issues'])} problema(s) a revisar antes de la entrega a mastering."
            else:
                out["summary"] = f"‚ö†Ô∏è {len(out['issues'])} issue(s) to review before mastering delivery."
        return out


    def _localize_report(r: dict) -> dict:
        """
        Minimal post-processing for edge cases.
        Most localization is now handled at the source.
        """
        # No changes needed - all localization done at source
        return r

    reports_out = []
    for r in reports:
        r_out = _notes_only_view(r) if args.notes_only else r
        r_out = _localize_report(r_out)
        reports_out.append(r_out)

        # ==================== SHORT MODE ====================
        # Tips-only output: verdict + score + recommendations
        # Perfect for WhatsApp, web UI, quick feedback
        if args.short:
            # Check if this is a mastered track
            score = r_out.get('score', 0)
            metrics = r_out.get('metrics', [])
            
            # Detect mastered track (same logic as write_report)
            lufs_metric = next((m for m in metrics if "LUFS" in m.get("internal_key", "")), None)
            peak_metric = next((m for m in metrics if "Headroom" in m.get("internal_key", "")), None)
            tp_metric = next((m for m in metrics if "True Peak" in m.get("internal_key", "")), None)
            
            lufs_value = None
            if lufs_metric and lufs_metric.get("value") != "N/A":
                try:
                    lufs_value = float(lufs_metric.get("value", "").split()[0])
                except:
                    pass
            
            peak_value = None
            if peak_metric:
                try:
                    peak_str = peak_metric.get("peak_db", "")
                    peak_value = float(peak_str.replace(" dBFS", "").replace("dBFS", ""))
                except:
                    pass
            
            tp_value = None
            if tp_metric:
                try:
                    tp_str = tp_metric.get("value", "")
                    tp_value = float(tp_str.replace(" dBTP", "").replace("dBTP", ""))
                except:
                    pass
            
            is_mastered = False
            if lufs_value is not None and lufs_value > -14:
                if (peak_value is not None and peak_value > -1.0) or (tp_value is not None and tp_value > -1.0):
                    is_mastered = True
            
            print()
            # Show filename in short mode
            if lang == 'es':
                print(f"üéµ {f.name}")
            else:
                print(f"üéµ {f.name}")
            print(UI_TEXT[lang]["short_header"])
            print(UI_TEXT[lang]["short_separator"])
            
            if is_mastered:
                # Special output for mastered tracks with updated CTA (no score/verdict)
                print()
                if lang == 'es':
                    print("üéõÔ∏è Tipo: M√°ster Finalizado")
                    print()
                    print("üíº Este archivo parece ser un master o hotmix.")
                    print()
                    print("Si tu intenci√≥n era enviar una mezcla para mastering, necesitas:")
                    print("‚Ä¢ Volver a la sesi√≥n sin limitador en el bus maestro")
                    print("‚Ä¢ Bajar ~6 dB (picos en -6 dBFS)")
                    print("‚Ä¢ Re-exportar la mezcla")
                    print()
                    print("¬øQuieres hacer los ajustes, subirla de nuevo y revisar si ya est√°")
                    print("lista para masterizar? O si prefieres, puedo ayudarte a dejarla")
                    print("lista como mezcla para luego masterizarla.")
                    print()
                    print("Sube los archivos y con gusto te la preparo.")
                else:
                    print("üéõÔ∏è Type: Finished Master")
                    print()
                    print("üíº This file appears to be a master or hotmix.")
                    print()
                    print("If your goal was to send a mix for mastering, you need:")
                    print("‚Ä¢ Go back to session without limiter on master bus")
                    print("‚Ä¢ Lower ~6 dB (peaks at -6 dBFS)")
                    print("‚Ä¢ Re-export the mix")
                    print()
                    print("Want to make the adjustments yourself, re-upload it, and check if it's")
                    print("ready for mastering? Or if you prefer, I can help you get it ready")
                    print("as a mix and then master it.")
                    print()
                    print("Upload the files and I'll gladly prep it for you.")
            else:
                # Normal short output for mixes
                print(f"\nüìä Score: {score}/100")
                print(f"üéØ {r_out.get('verdict', '')}")
                print()
                recs = r_out.get("notes", {}).get("recommendations", [])
                if recs:
                    if lang == 'es':
                        print("üí° Recomendaciones:")
                    else:
                        print("üí° Recommendations:")
                    for rec in recs:
                        print(f"  {rec}")
                
                # Add CTA for normal mixes
                cta = generate_cta(score, args.strict, lang, mode="short")
                print(cta)
            
            print()
            continue  # Skip JSON output

        # ==================== WRITE MODE ====================
        # Narrative engineer-style feedback
        # Perfect for emails, reports, web copy
        if args.write:
            narrative = write_report(r_out, args.strict, lang, filename=f.name)
            print()
            print(narrative)
            print()
            continue  # Skip JSON output

        # ==================== NORMAL/NOTES-ONLY MODE ====================
        # Full JSON output (default behavior)
        print("\n" + "="*60)
        print(UI_TEXT[lang]["analysis_results"])
        print("="*60)
        print(json.dumps(r_out, ensure_ascii=False, indent=2))

    # Save JSON
    if args.json_path:

        outp = Path(args.json_path).expanduser()
        try:
            if len(reports_out) == 1:
                outp.write_text(json.dumps(reports_out[0], ensure_ascii=False, indent=2), encoding="utf-8")
            else:
                outp.write_text(json.dumps(reports_out, ensure_ascii=False, indent=2), encoding="utf-8")
            print(f"\n‚úÖ Reporte guardado en: {outp}")
        except Exception as e:
            print(f"‚ùå Error guardando JSON: {e}", file=sys.stderr)


if __name__ == "__main__":
    main()

